{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "k0I3dV9kCO0G",
        "tR35FEAfD4rt"
      ],
      "authorship_tag": "ABX9TyMWz6u4AdK5igNsIETuFKpw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archei2500/overdubbing_courses/blob/main/lip_sync.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Добро пожаловать в интерактивную систему для синхронизации движений губ с речью!**\n",
        "\n",
        "> Здесь вы можете выполнить синхронизацию движений губ с речью в видео на основе файла с субтитрами (расшифровкой) с временными метками.\n",
        "\n",
        "> Пожалуйста, следуйте инструкциям.\n",
        "1.   Для начала перейдите к первому разделу, укажите, нужно ли вам автоматическое улучшение качества после обработки (после анимации губ качество получается хуже), и запустите ячейку. В среду установится всё необходимое для работы.\n",
        "2.   Перейдите ко второму разделу: загрузите видео и текст с субтитрами (текстом видео с временными метками) в систему любым удобным способом из предложенных.\n",
        "3.   В разделе ниже выполните синхронизацию губ с речью, выбрав номера фраз из вашего файла с субтитрами, модель и некоторые параметры по желанию. Ожидайте результата.\n",
        "\n",
        ">О моделях для синхронизации губ:\n",
        "1.  Классический Wav2Lip. В данном случае движение губ хорошо синхронизируется с аудиодорожкой. Недостаток - качество изображения на месте губ получается очень плохим. Но после этого можно воспользоваться нейросетью для улучшения качества изображения.\n",
        "2. Wav2Lip + GAN. Движение губ синхронизируется с аудиодорожкой хуже. Небольшая амплитуда открывания рта. Качество изображения лучше по сравнению с Wav2Lip без GAN. Выглядит наиболее естественно.\n",
        "3. VideoReTalking. Амплитуда открывания рта больше. Качество изображения низкое. Также желательно применить далее нейросеть для улучшения качества изображения.\n",
        "\n",
        "> *Примечание: в каждом кадре указанных фрагментов должно быть лицо.*\n",
        "\n",
        "> ***Убедитесь в том, что вы подключены к среде с GPU!!!***"
      ],
      "metadata": {
        "id": "umK88l6PuXcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Запустить перед началом работы"
      ],
      "metadata": {
        "id": "uzn-F3pyAmrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Нужно ли улучшать качество видео после обработки?\n",
        "gfpgan = False # @param {type: \"boolean\"}\n",
        "\n",
        "!pip install ffmpeg-python\n",
        "!pip install moviepy\n",
        "!pip install pydub\n",
        "!pip install torchvision==0.16.2 # более старая версия для совместимости\n",
        "if gfpgan:\n",
        "  # установка GFPGAN для улучшения качества кадров\n",
        "  !git clone https://github.com/TencentARC/GFPGAN.git\n",
        "\n",
        "  !pip install basicsr\n",
        "  !pip install facexlib\n",
        "  !pip install -r requirements.txt\n",
        "  !python setup.py develop\n",
        "  !pip install realesrgan # используется для увеличения разрешения фоновых (не лицевых) областей\n",
        "\n",
        "  # Загрузка предобученной модели\n",
        "  !wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models\n",
        "\n",
        "  import numpy as np\n",
        "  import glob\n",
        "  import subprocess\n",
        "from pydub import AudioSegment\n",
        "from IPython.display import clear_output\n",
        "import os\n",
        "from google.colab import files\n",
        "import ffmpeg\n",
        "import re\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip, concatenate_videoclips\n",
        "import cv2\n",
        "from tensorflow.test import gpu_device_name\n",
        "\n",
        "\n",
        "def str_to_time(s):\n",
        "  return int(s[6:8]) + 60 * int(s[3:5]) + 3600 * int(s[:2]) + float('0.' + s[9:12])\n",
        "\n",
        "\n",
        "def time_to_str(time):\n",
        "  hours = int(time // 3600)\n",
        "  minutes = int((time - 3600 * hours) // 60)\n",
        "  seconds = time - 60 * minutes\n",
        "  str_sec = str(round(seconds, 3)).replace('.', ',')\n",
        "  return str(hours).zfill(2) + ':' + str(minutes).zfill(2) + ':' + str_sec[:str_sec.find(',')].zfill(2) + ',' + str_sec[str_sec.find(',') + 1:].ljust(3, '0')\n",
        "\n",
        "\n",
        "def extract_number(s):\n",
        "  match = re.search(r'\\d+', s) # регулярное выражение \\d+ означает \"одна или более цифр подряд\"\n",
        "  if match:\n",
        "    return int(match.group())\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "def convert_frames_to_video(path_in, path_out, fps):\n",
        "  frame_array = []\n",
        "  files = [join(path_in, f) for f in os.listdir(path_in) if isfile(join(path_in, f))]\n",
        "  files = sorted(files, key = extract_number)\n",
        "\n",
        "  for file in files:\n",
        "    # чтение файлов с кадрами\n",
        "    img = cv2.imread(file)\n",
        "    height, width, layers = img.shape\n",
        "    size = (width, height)\n",
        "    # добавление кадров в список изображений\n",
        "    frame_array.append(img)\n",
        "  out = cv2.VideoWriter(path_out, cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
        "  for i in range(len(frame_array)):\n",
        "    # запись списка изображений в качестве видео\n",
        "    out.write(frame_array[i])\n",
        "  out.release()\n",
        "\n",
        "\n",
        "wav2lip_installed = False\n",
        "vidretalk_installed = False\n",
        "\n",
        "path_to_text = '/content/subtitles.srt'\n",
        "path_to_video = '/content/vid.mp4'\n",
        "path_to_auds = '/content/aud_fragms'\n",
        "path_to_vids = '/content/vid_fragms'\n",
        "path_to_lip_res = '/content/lip_results'\n",
        "\n",
        "# проверка того, что пользователь подключен к среде GPU\n",
        "device_name = gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU не найден! Совет: подключитесь к среде с GPU.')\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "rb2_StJ_At2k",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка видео и файла с субтитрами (расшифровкой)"
      ],
      "metadata": {
        "id": "k0I3dV9kCO0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Загрузка видео\n",
        "#@markdown ### Способ загрузки\n",
        "upload_method = \"С устройства\" #@param [\"С устройства\", \"По ссылке с YouTube\", \"Путь к файлу Google Drive\"]\n",
        "#@markdown <font color=\"orange\"> Примечания и советы:\n",
        "\n",
        "#@markdown <font color=\"orange\"> ``1. При выборе загрузки с устройства нужно будет нажать на кнопку в выходных данных и выбрать файл с устройства.``\n",
        "\n",
        "#@markdown <font color=\"orange\"> ``2. Для загрузки с YouTube укажите ссылку в соответствующее поле.``\n",
        "\n",
        "#@markdown <font color=\"orange\"> ``3. Обратите внимание: при выборе способа, связанного с Google Диском, система попросит вас дать разрешение на доступ к вашему Google Drive. Затем он будет смонтирован в файловую систему. После этого укажите путь к файлу в соответствующем поле.``\n",
        "\n",
        "#@markdown ``Вставьте ссылку на видеоролик с платформы YouTube в требуемом формате `` 👇\n",
        "youtube_url = 'https://www.youtube.com/watch?v=YOUTUBE_ID' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ``Введите полный путь к видео на вашем Google Диске (для варианта с загрузкой с Google Drive) `` 👇\n",
        "path_google_drive = '/content/drive/MyDrive/path_to_vid' #@param {type:\"string\"}\n",
        "\n",
        "from urllib import parse as urlparse\n",
        "\n",
        "# Удаление файлов, если такие уже были в ФС прежде\n",
        "if os.path.isfile(path_to_video):\n",
        "    os.remove(path_to_video)\n",
        "if os.path.isfile('/content/aud.wav'):\n",
        "    os.remove('/content/aud.wav')\n",
        "\n",
        "path_to_video = '/content/vid.mp4' # путь к видео по умолчанию\n",
        "\n",
        "# Видеофайл загружается разными способами\n",
        "if upload_method == \"С устройства\":\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    if '/content/' + filename != path_to_video:\n",
        "      os.rename(filename, path_to_video)  # переименование загруженного файла\n",
        "elif upload_method == \"По ссылке с YouTube\":\n",
        "  if not yt_downloaded:\n",
        "    !pip install yt-dlp # установка при первом запуске\n",
        "    yt_downloaded = True\n",
        "  url_data = urlparse.urlparse(youtube_url)\n",
        "  query = urlparse.parse_qs(url_data.query)\n",
        "  YOUTUBE_ID = query[\"v\"][0]\n",
        "  # Загрузка видео с YouTube\n",
        "  !yt-dlp -f \"bestvideo[ext=mp4]+bestaudio[ext=wav]/best[ext=mp4]/best\" --output \"/content/vid.%(ext)s\" https://www.youtube.com/watch?v=$YOUTUBE_ID\n",
        "  # Запоминаем путь к файлу\n",
        "  for file in os.listdir('/content'):\n",
        "    if file.startswith('vid'):\n",
        "        path_to_video = os.path.join(directory, file)\n",
        "else:\n",
        "  if not gd_mounted:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\") # монтирование Google Диска при первом запуске\n",
        "    gd_mounted = True\n",
        "  if not os.path.isfile(path_google_drive): # если файл не найден\n",
        "      print(\"ERROR: File not found!\")\n",
        "      raise SystemExit(0)\n",
        "  !cp $path_google_drive $path_to_video # копирование файла с Google Диска\n",
        "\n",
        "# извлечение аудиодорожки из видео\n",
        "video = VideoFileClip(path_to_video)\n",
        "video.audio.write_audiofile('/content/aud.wav') # извлечение аудиодорожки\n",
        "\n",
        "clear_output() # очистка выходных данных"
      ],
      "metadata": {
        "cellView": "form",
        "id": "BoAdZA3rCTBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Загрузка субтитров (файла со структурой SRT)\n",
        "\n",
        "# @markdown Выберите метод загрузки и укажите путь к файлу, если привязываете Google Диск:\n",
        "# @markdown ### Способ загрузки\n",
        "upload_method = \"С устройства\" #@param [\"С устройства\", \"Путь к файлу Google Drive\"]\n",
        "#@markdown <font color=\"orange\"> Примечания и советы:\n",
        "\n",
        "#@markdown <font color=\"orange\"> ``1. При выборе загрузки с устройства нужно будет нажать на кнопку в выходных данных и выбрать файл с устройства.``\n",
        "\n",
        "#@markdown <font color=\"orange\"> ``2. Обратите внимание: при выборе способа, связанного с Google Диском, система попросит вас дать разрешение на доступ к вашему Google Drive. Затем он будет смонтирован в файловую систему. После этого укажите путь к файлу в соответствующем поле.``\n",
        "\n",
        "#@markdown ``Введите полный путь к видео на вашем Google Диске (для варианта с загрузкой с Google Drive) `` 👇\n",
        "path_google_drive = '/content/drive/MyDrive/path_to_subs' #@param {type:\"string\"}\n",
        "\n",
        "# Удаление файла, если такой уже был в ФС прежде\n",
        "if os.path.isfile(path_to_text):\n",
        "    os.remove(path_to_text)\n",
        "\n",
        "path_to_text = '/content/subtitles.srt' # путь к файлу по умолчанию\n",
        "\n",
        "# Видеофайл загружается разными способами\n",
        "if upload_method == \"С устройства\":\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    if not (filename.endswith('.srt') or filename.endswith('.txt')):\n",
        "      print(\"Файл должен иметь расширение SRT или TXT!\")\n",
        "      raise SystemExit(0)\n",
        "    if '/content/' + filename != path_to_text:\n",
        "      os.rename(filename, path_to_text) # переименование загруженного файла\n",
        "else:\n",
        "  if not gd_mounted:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\") # монтирование Google Диска при первом запуске\n",
        "    gd_mounted = True\n",
        "  if not os.path.isfile(path_google_drive): # если файл не найден\n",
        "    print(\"ERROR: File not found!\")\n",
        "    raise SystemExit(0)\n",
        "  if not (path_google_drive.endswith('.srt') or path_google_drive.endswith('.srt')):\n",
        "    print(\"Файл должен иметь расширение SRT или TXT!\")\n",
        "    raise SystemExit(0)\n",
        "  !cp $path_google_drive $path_to_text # копирование файла с Google Диска\n",
        "\n",
        "# Проверка на то, что файл имеет необходимую структуру\n",
        "if check_txtfile(path_to_text):\n",
        "  clear_output()\n",
        "else:\n",
        "  print('Неверная структура выбранного файла!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "c8ol6mXlDuLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Синхронизация"
      ],
      "metadata": {
        "id": "kNVW0UHgD1wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Синхронизируйте движения губ с речью в выбранных фрагментах\n",
        "# @markdown Укажите номера фрагментов из вашего файла с субтитрами (отсчёт от 1) через пробел:\n",
        "timings_str = '1 32' # @param {type: \"string\"}\n",
        "if timings_str:\n",
        "  try:\n",
        "    timings = [int(n) for n in timings_str.split()]\n",
        "    timings.sort() # сортировка по возрастанию\n",
        "  except ValueError:\n",
        "    print('Вы некорректно ввели номера фрагментов. Попробуйте снова.')\n",
        "    raise SystemExit(0)\n",
        "else:\n",
        "  print('Необходимо ввести номера фрагментов.')\n",
        "\n",
        "# @markdown Выберите модель для анимации губ:\n",
        "lip_tool = 'Wav2Lip' #@param [\"Wav2Lip\", \"Wav2Lip + GAN\", \"VideoReTalking\"]\n",
        "# @markdown <font color = \"orange\"> Примечание: ``Учтите, что установка VideoReTalking может занимать около 15 минут.``\n",
        "\n",
        "# @markdown ___\n",
        "\n",
        "# @markdown ***Следующие настройки только для Wav2Lip или Wav2Lip + GAN:***\n",
        "\n",
        "# @markdown Настройка рамки вокруг рта. Так регулируются отступы. Вы можете задействовать область подбородка, например, задав pad_bottom = 20.\n",
        "pad_top = 0 #@param {type: \"integer\"}\n",
        "pad_bottom = 0 #@param {type: \"integer\"}\n",
        "pad_left = 0 #@param {type: \"integer\"}\n",
        "pad_right = 0 #@param {type: \"integer\"}\n",
        "# @markdown Чтобы не было чрезмерного сглаживания изображений лица, можно задать nosmooth:\n",
        "nosmooth = True #@param {type: \"boolean\"}\n",
        "# @markdown Можно уменьшить разрешение видео для лучшего результата, так как модели обучались на лицах с более низким разрешением. На это число будут нацело делиться ширина и высота каждого кадра.\n",
        "resize = 1 #@param {type: \"integer\"}\n",
        "\n",
        "# @markdown ___\n",
        "# Скачать результат?\n",
        "download_file = True #@param {type: \"boolean\"}\n",
        "\n",
        "# проверка на то, что необходимые файлы были загружены\n",
        "if os.path.isfile(path_to_video) and os.path.isfile(path_to_text):\n",
        "  # чтение файла, чтобы взять оттуда тайминги по номерам\n",
        "  txt_file = open(path_to_subs, 'r', encoding = 'utf-8')\n",
        "  lines = [''] + txt_file.read().split('\\n')\n",
        "  txt_file.close()\n",
        "\n",
        "  # проверка на принадлежность существующему диапазону таймингов, введённых пользователем\n",
        "  if timings[0] >= 1 and timings[-1] <= len(lines) / 4:\n",
        "    # создание папок для хранения аудио- и видеофрагментов\n",
        "    !mkdir $path_to_auds\n",
        "    !mkdir $path_to_vids\n",
        "\n",
        "    # из видео вырезаются фрагменты для анимации губ\n",
        "    for i, timing in enumerate(timings):\n",
        "      start = str_to_time(lines[(timing - 1) * 4 + 2][:lines[(timing - 1) * 4 + 2].find(' ')])\n",
        "      end = str_to_time(lines[(timing - 1) * 4 + 2][lines[(timing - 1) * 4 + 2].rfind(' ') + 1:])\n",
        "      out_path = path_to_vids + '/' + str(i) + '.mp4'\n",
        "      # фрагмент вырезается по таймингу\n",
        "      !ffmpeg -y -i $video_path -ss {start + 0.001} -to {end} -async 1 $out_path\n",
        "      # извлечение аудиодорожки с проверкой на то, что аудио и видео точно одной продолжительности\n",
        "      video = VideoFileClip(out_path)\n",
        "      video.audio.write_audiofile(path_to_auds + '/' + str(i) + '.wav') # извлечение аудиодорожки\n",
        "      difference = video.duration - len(AudioSegment.from_file(path_to_auds + '/' + str(i) + '.wav')) / 1000\n",
        "      if difference > 0:\n",
        "        !rm $out_path\n",
        "        !ffmpeg -y -i $video_path -to {video.duration - difference} -async 1 $out_path\n",
        "\n",
        "    # фрагменты заносятся в списки и сортируются по возрастанию\n",
        "    lip_fragments_list = [path_to_vids + '/' + item for item in os.listdir(path_to_vids) if '.ipynb' not in item]\n",
        "    lip_fragments_list = sorted(lip_fragments_list, key = extract_number)\n",
        "    aud_fragments_list = [path_to_auds + '/' + item for item in os.listdir(path_to_auds) if '.ipynb' not in item]\n",
        "    aud_fragments_list = sorted(aud_fragments_list, key = extract_number)\n",
        "\n",
        "    !mkdir $path_to_lip_res # создание папки для результатов lip sync\n",
        "\n",
        "    if lip_tool == 'Wav2Lip' or lip_tool == 'Wav2Lip + GAN':\n",
        "      if not wav2lip_installed:\n",
        "        # установка wav2lip\n",
        "        !git clone https://github.com/justinjohn0306/Wav2Lip\n",
        "        %cd /content/Wav2Lip\n",
        "        # загрузка предобученных моделей\n",
        "        !wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/wav2lip.pth' -O 'checkpoints/wav2lip.pth'\n",
        "        !wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/wav2lip_gan.pth' -O 'checkpoints/wav2lip_gan.pth'\n",
        "        !wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/resnet50.pth' -O 'checkpoints/resnet50.pth'\n",
        "        !wget 'https://github.com/justinjohn0306/Wav2Lip/releases/download/models/mobilenet.pth' -O 'checkpoints/mobilenet.pth'\n",
        "        a = !pip install https://raw.githubusercontent.com/AwaleSajil/ghc/master/ghc-1.0-py3-none-any.whl\n",
        "        !pip install git+https://github.com/elliottzheng/batch-face.git@master\n",
        "        %cd /content\n",
        "\n",
        "        wav2lip_installed = True\n",
        "\n",
        "      # выбирается одна из моделей\n",
        "      checkpoint_path = 'checkpoints/wav2lip.pth' if lip_tool == 'Wav2Lip' else 'checkpoints/wav2lip_gan.pth'\n",
        "\n",
        "      # синхронизация губ\n",
        "      for i, lip_fragm in enumerate(lip_fragments_list):\n",
        "        output_file_path = path_to_lip_res + '/' + str(i) + '.mp4'\n",
        "        face_path = lip_fragm\n",
        "        audio_path = aud_fragments_list[i]\n",
        "\n",
        "        if nosmooth == False:\n",
        "          command = f\"cd Wav2Lip && python inference.py --checkpoint_path {checkpoint_path} --face {face_path} --audio {audio_path} --outfile {output_file_path} --pads {pad_top} {pad_bottom} {pad_left} {pad_right} --resize_factor {resize}\"\n",
        "          !{command}\n",
        "        else:\n",
        "          command = f\"cd Wav2Lip && python inference.py --checkpoint_path {checkpoint_path} --face {face_path} --audio {audio_path} --outfile {output_file_path} --pads {pad_top} {pad_bottom} {pad_left} {pad_right} --resize_factor {resize} --nosmooth\"\n",
        "          !{command}\n",
        "\n",
        "        # Увеличение размеров кадров после обработки, т. к. они уменьшаются\n",
        "        vcap1 = cv2.VideoCapture(face_path) # старое видео до Wav2Lip\n",
        "        vcap2 = cv2.VideoCapture(output_file_path) # новое видео после Wav2Lip\n",
        "        fps = vcap2.get(cv2.CAP_PROP_FPS)\n",
        "        new_width  = vcap1.get(cv2.CAP_PROP_FRAME_WIDTH) # float\n",
        "        new_height = vcap1.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "        out = cv2.VideoWriter('resized_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (int(new_width), int(new_height))) # создание объекта для записи видео\n",
        "\n",
        "        while True:\n",
        "          ret, frame = vcap2.read()\n",
        "          if not ret:\n",
        "              break\n",
        "\n",
        "          # Изменение размеров кадра\n",
        "          resized_frame = cv2.resize(frame, (int(new_width), int(new_height)))\n",
        "          # Запись измененного кадра в новое видео\n",
        "          out.write(resized_frame)\n",
        "          #cv2.imwrite(resized_frame)\n",
        "\n",
        "        # Освобождение ресурсов\n",
        "        vcap1.release()\n",
        "        vcap2.release()\n",
        "        out.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "        os.remove(output_file_path)\n",
        "        os.rename('resized_video.mp4', output_file_path)\n",
        "\n",
        "    else:\n",
        "      if not vidretalk_installed:\n",
        "        !python --version\n",
        "        !apt-get update\n",
        "        !apt install ffmpeg &> /dev/null\n",
        "        !git clone https://github.com/vinthony/video-retalking.git &> /dev/null\n",
        "        %cd video-retalking\n",
        "        !pip install -r requirements.txt\n",
        "        !pip install numpy==1.23.0\n",
        "        # проверить, какая зависимость нужна, т. к. что-то, связанное с torchvision, устарело\n",
        "        #!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "        # загрузка предобученных моделей\n",
        "        !mkdir ./checkpoints\n",
        "        !wget https://github.com/vinthony/video-retalking/releases/download/v0.0.1/30_net_gen.pth -O ./checkpoints/30_net_gen.pth\n",
        "        !wget https://github.com/vinthony/video-retalking/releases/download/v0.0.1/BFM.zip -O ./checkpoints/BFM.zip\n",
        "        !wget https://github.com/vinthony/video-retalking/releases/download/v0.0.1/DNet.pt -O ./checkpoints/DNet.pt\n",
        "        !wget https://github.com/vinthony/video-retalking/releases/download/v0.0.1/ENet.pth -O ./checkpoints/ENet.pth\n",
        "        !wget https://github.com/vinthony/video-retalking/releases/download/v0.0.1/expression.mat -O ./checkpoints/expression.mat\n",
        "        !wget https://github.com/vinthony/video-retalking/releases/download/v0.0.1/face3d_pretrain_epoch_20.pth -O ./checkpoints/face3d_pretrain_epoch_20.pth\n",
        "        !wget https://github.com/vinthony/video-retalking/releases/download/v0.0.1/GFPGANv1.3.pth -O ./checkpoints/GFPGANv1.3.pth\n",
        "        !wget https://github.com/vinthony/video-retalking/releases/download/v0.0.1/GPEN-BFR-512.pth -O ./checkpoints/GPEN-BFR-512.pth\n",
        "        !wget https://github.com/vinthony/video-retalking/releases/download/v0.0.1/LNet.pth -O ./checkpoints/LNet.pth\n",
        "        !wget https://github.com/vinthony/video-retalking/releases/download/v0.0.1/ParseNet-latest.pth -O ./checkpoints/ParseNet-latest.pth\n",
        "        !wget https://github.com/vinthony/video-retalking/releases/download/v0.0.1/RetinaFace-R50.pth -O ./checkpoints/RetinaFace-R50.pth\n",
        "        !wget https://github.com/vinthony/video-retalking/releases/download/v0.0.1/shape_predictor_68_face_landmarks.dat -O ./checkpoints/shape_predictor_68_face_landmarks.dat\n",
        "        !unzip -d ./checkpoints/BFM ./checkpoints/BFM.zip\n",
        "        %cd /content\n",
        "\n",
        "        vidretalk_installed = True\n",
        "\n",
        "        # синхронизация губ\n",
        "        !cd video-retalking && python3 inference.py \\\n",
        "          --face {face_path} \\\n",
        "          --audio {audio_path} \\\n",
        "          --outfile {output_file_path}\n",
        "\n",
        "    %cd /content\n",
        "    # Улучшение качества кадров в видео с анимацией губ\n",
        "    if gfpgan:\n",
        "      !mkdir /content/results\n",
        "      !mkdir /content/results_videos\n",
        "      !mkdir /content/results_mp4_videos\n",
        "\n",
        "      for i, timing in enumerate(timings):\n",
        "        lip_fragm = '/content/lip_results/' + str(i) + '.mp4'\n",
        "\n",
        "        if os.path.exists(lip_fragm):\n",
        "          # преобразование видео в фреймы\n",
        "          vid_stream = cv2.VideoCapture(lip_fragm)\n",
        "          fps = vid_stream.get(cv2.CAP_PROP_FPS) # получаем fps\n",
        "\n",
        "          !mkdir /content/vid_frames\n",
        "\n",
        "          # сохранение всех кадров из видео\n",
        "          current_frame = 0\n",
        "          while (True):\n",
        "            # cap.read() в ret возвращает значение типа boolean. Если frame прочитан корректно: ret = True.\n",
        "            ret, frame = vid_stream.read()\n",
        "            print(ret)\n",
        "\n",
        "            if ret:\n",
        "              frame_path = '/content/vid_frames/frame' + str(current_frame) + '.jpg'\n",
        "              cv2.imwrite(frame_path, frame)\n",
        "              # увеличение значения счётчика кадров\n",
        "              current_frame += 1\n",
        "            else:\n",
        "              break\n",
        "\n",
        "          vid_stream.release()\n",
        "          cv2.destroyAllWindows()\n",
        "\n",
        "          # улучшение кадров\n",
        "          !cd GFPGAN && python inference_gfpgan.py -i /content/vid_frames -o /content/results -v 1.3 -s 1 --bg_upsampler realesrgan # на 1.3 поменять возможно потом, но для этого установить тоже 1.3 версию\n",
        "\n",
        "          for f in os.listdir('/content/vid_frames'):\n",
        "            os.remove(os.path.join('/content/vid_frames', f))\n",
        "\n",
        "          # конвертирование super res frames to .avi\n",
        "          path_out = \"/content/results_videos/\" + str(i) + '.avi'\n",
        "          # fps видео\n",
        "          convert_frames_to_video('/content/results/restored_imgs/', path_out, fps)\n",
        "\n",
        "          for f in os.listdir('/content/results/restored_imgs'):\n",
        "            os.remove(os.path.join('/content/results/restored_imgs', f))\n",
        "\n",
        "          # конвертирование .avi to .mp4\n",
        "          src = '/content/results_videos/'\n",
        "          dst = '/content/results_mp4_videos/'\n",
        "\n",
        "          for root, dirs, filenames in os.walk(src, topdown = False):\n",
        "            for filename in filenames:\n",
        "              try:\n",
        "                _format = ''\n",
        "                if \".flv\" in filename.lower():\n",
        "                    _format=\".flv\"\n",
        "                if \".mp4\" in filename.lower():\n",
        "                    _format=\".mp4\"\n",
        "                if \".avi\" in filename.lower():\n",
        "                    _format=\".avi\"\n",
        "                if \".mov\" in filename.lower():\n",
        "                    _format=\".mov\"\n",
        "\n",
        "                inputfile = os.path.join(root, filename)\n",
        "                outputfile = os.path.join(dst, filename.lower().replace(_format, \".mp4\"))\n",
        "                subprocess.call(['ffmpeg', '-i', inputfile, outputfile])\n",
        "              except:\n",
        "                print(\"An exception occurred\")\n",
        "\n",
        "          for f in os.listdir('/content/results_videos'):\n",
        "            os.remove(os.path.join('/content/results_videos', f))\n",
        "\n",
        "      # Копирование улучшенных видео в lip_results\n",
        "      for i, timing in enumerate(timings):\n",
        "        lip_fragm = '/content/lip_results/' + str(i) + '.mp4'\n",
        "        new_lip_fragm = '/content/results_mp4_videos/' + str(i) + '.mp4'\n",
        "        !cp {new_lip_fragm} {lip_fragm}\n",
        "\n",
        "    # Итоговая нарезка\n",
        "    counter = 0\n",
        "    for i, timing in enumerate(timings):\n",
        "      lip_fragm = '/content/lip_results/' + str(i) + '.mp4'\n",
        "      old_aud = '/content/aud_fragms/' + str(i) + '.wav'\n",
        "      end = str_to_time(lines[(timing - 1) * 4 + 2][:lines[(timing - 1) * 4 + 2].find(' ')])\n",
        "      out_path = '/content/fragments/' + str(counter) + '.mp4'\n",
        "      aud_path = '/content/audios/' + str(counter) + '.wav'\n",
        "      if len(timings) == 1: # единственный\n",
        "        !ffmpeg -y -i $video_path -to {end} -async 1 $out_path\n",
        "        audio = VideoFileClip(out_path).audio\n",
        "        audio.write_audiofile(aud_path)\n",
        "        counter += 1\n",
        "        os.rename(lip_fragm, '/content/fragments/' + str(counter) + '.mp4')\n",
        "        !cp {old_aud} {'/content/audios/' + str(counter) + '.wav'}\n",
        "        counter += 1\n",
        "        start = str_to_time(lines[(timing - 1) * 4 + 2][lines[(timing - 1) * 4 + 2].rfind(' ') + 1:])\n",
        "        if VideoFileClip(video_path).duration > start:\n",
        "          out_path = '/content/fragments/' + str(counter) + '.mp4'\n",
        "          aud_path = '/content/audios/' + str(counter) + '.wav'\n",
        "          !ffmpeg -y -i $video_path -ss {start + 0.001} -async 1 $out_path\n",
        "          audio = VideoFileClip(out_path).audio\n",
        "          audio.write_audiofile(aud_path)\n",
        "      elif i == 0: # если самый первый\n",
        "        !ffmpeg -y -i $video_path -to {end} -async 1 $out_path\n",
        "        audio = VideoFileClip(out_path).audio\n",
        "        audio.write_audiofile(aud_path)\n",
        "        counter += 1\n",
        "        os.rename(lip_fragm, '/content/fragments/' + str(counter) + '.mp4')\n",
        "        !cp {old_aud} {'/content/audios/' + str(counter) + '.wav'}\n",
        "        counter += 1\n",
        "        start = str_to_time(lines[(timing - 1) * 4 + 2][lines[(timing - 1) * 4 + 2].rfind(' ') + 1:])\n",
        "      elif i == len(timings) - 1: # если последний\n",
        "        !ffmpeg -y -i $video_path -ss {start + 0.001} -to {end} -async 1 $out_path\n",
        "        audio = VideoFileClip(out_path).audio\n",
        "        audio.write_audiofile(aud_path)\n",
        "        counter += 1\n",
        "        os.rename(lip_fragm, '/content/fragments/' + str(counter) + '.mp4')\n",
        "        !cp {old_aud} {'/content/audios/' + str(counter) + '.wav'}\n",
        "        counter += 1\n",
        "        start = str_to_time(lines[(timing - 1) * 4 + 2][lines[(timing - 1) * 4 + 2].rfind(' ') + 1:])\n",
        "        if VideoFileClip(video_path).duration > start:\n",
        "          out_path = '/content/fragments/' + str(counter) + '.mp4'\n",
        "          aud_path = '/content/audios/' + str(counter) + '.wav'\n",
        "          !ffmpeg -y -i $video_path -ss {start + 0.001} -async 1 $out_path\n",
        "          audio = VideoFileClip(out_path).audio\n",
        "          audio.write_audiofile(aud_path)\n",
        "      else: # обычный\n",
        "        end = str_to_time(lines[(timing - 1) * 4 + 2][:lines[(timing - 1) * 4 + 2].find(' ')])\n",
        "        !ffmpeg -y -i $video_path -ss {start + 0.001} -to {end} -async 1 $out_path\n",
        "        audio = VideoFileClip(out_path).audio\n",
        "        audio.write_audiofile(aud_path)\n",
        "        counter += 1\n",
        "        os.rename(lip_fragm, '/content/fragments/' + str(counter) + '.mp4')\n",
        "        !cp {old_aud} {'/content/audios/' + str(counter) + '.wav'}\n",
        "        counter += 1\n",
        "        start = str_to_time(lines[(timing - 1) * 4 + 2][lines[(timing - 1) * 4 + 2].rfind(' ') + 1:])\n",
        "\n",
        "    fragments = ['/content/fragments/' + item for item in os.listdir('/content/fragments') if '.ipynb' not in item]\n",
        "    fragments = sorted(fragments, key = extract_number)\n",
        "\n",
        "    loaded_video_list = []\n",
        "    # склеиваем все фрагменты\n",
        "    for fragment in fragments:\n",
        "      loaded_video_list.append(VideoFileClip(fragment))\n",
        "    concatenate_clip = concatenate_videoclips(loaded_video_list, method = 'compose')\n",
        "    concatenate_clip.write_videofile('/content/result.mp4', logger = None)\n",
        "\n",
        "    # Накладываем аудиодорожку\n",
        "    !ffmpeg -i /content/result.mp4 -i /content/aud.wav -c:v copy -c:a aac -strict experimental -map 0:v:0 -map 1:a:0 /content/final_video.mp4\n",
        "    if download_file:\n",
        "      files.download('/content/final_video.mp4')\n",
        "    print('Готово. Результат вы найдёте по пути /content/final_video.mp4')\n",
        "  else:\n",
        "    print('Вы загрузили файл, который содержит ', int(len(times) / 4), ' фрагментов, но ввели ', timings_str)\n",
        "else:\n",
        "  if not os.path.isfile(path_to_video):\n",
        "    print('Вы не загрузили видео. Пожалуйста, вернитесь к предыдущим ячейкам и загрузите его.')\n",
        "  if not os.path.isfile(path_to_text):\n",
        "    print('Вы не загрузили субтитры. Пожалуйста, вернитесь к предыдущим ячейкам и загрузите их.')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_OSL2r0iD3jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Размонтировать Google Drive"
      ],
      "metadata": {
        "id": "tR35FEAfD4rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "BEGq8j9KD7lC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}