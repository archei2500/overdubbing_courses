{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mfkRU81vby8Z",
        "6Tz7lmci99Rd",
        "o3fSu0qeDQur"
      ],
      "authorship_tag": "ABX9TyNwUqKl3YQ0+Zxqp9NcAdPZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archei2500/overdubbing_courses/blob/main/video_dubbing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Добро пожаловать в интерактивную систему для озвучивания видео!**\n",
        "\n",
        "> Здесь вы можете:\n",
        "*   выполнить синтез речи с помощью 5 различных инструментов на основе файла со структурой SRT;\n",
        "*   протестировать некоторые инструменты для синтеза речи и получить рекомендации по их выбору для вашей ситуации;\n",
        "*   переозвучить видео (заменить аудиодорожку с речью на синтезированную) несколькими способами.\n",
        "\n",
        "> Пожалуйста, следуйте инструкциям.\n",
        "\n",
        "> Последовательность работы с блокнотом подразумевается такой:\n",
        "1.   Для начала перейдите к первому разделу и запустите ячейку. В среду установится всё необходимое для работы. *Это нужно сделать при любом сценарии работы*.\n",
        "2.   Перейдите ко второму разделу (разверните его, как и следующие): загрузите в систему файл, имеющий структуру SRT (т. е. субтитры, с временными интервалами), для синтеза речи, видео, которое будет переозвучиваться, и образец голоса для клонирования (если оно требуется - РЕКОМЕНДУЕТСЯ ФОРМАТ WAV) любым удобным способом из предложенных. Необязательно загружать всё сразу. *Система уведомит вас, если вы забудете что-то загрузить и попытаетесь выполнить код, где это нужно.*\n",
        "3.   Перейдите к синтезу речи. Для начала вы можете получить рекомендации по выбору инструмента для синтеза во второй ячейке раздела. Потребуется указать ваши предпочтения (язык синтеза и другие параметры). Затем на их основе вам будет выдан список возможных инструментов, моделей и голосов. Некоторые из инструментов доступны для тестирования в третьей ячейке раздела. После того, как вы определитесь с выбором, заполните поля первой ячейки и запустите её. После этого будут синтезированы фразы по отдельности. Вы можете скачать zip-архив с ними.\n",
        "4. Перейдите к клонированию голоса и выберите инструмент. Вы также получите wav-файлы с фразами, но с изменённым голосом, которые вы также сможете скачать как zip-архив.\n",
        "5. Теперь синтезированная речь может быть наложена на видео вместо оригинальной. Выберите один из двух вариантов с их опциями в зависимости от того, что вам нужно: достаточно простого соответствия фраз времени их начала, нужно подгонять фразы под временные отрезки, или видео должно быть чётко синхронизировано с новыми фразами при их исходной равной скорости. *Для последнего варианта необходимо запустить ячейку с нарезкой видео на фрагменты.* В результате вы получите переозвученное видео.\n",
        "\n",
        "> *Примечание 1: Вы можете загрузить синтезированные фразы и фрагменты видео в систему в разделе загрузок в виде zip-архивов. Это позволит вам возвращаться к процессу в удобное для вас время без необходимости проделывать всё с нуля.*\n",
        "\n",
        "> ***Желательно подключаться к среде с GPU, если планируете выполнять этап синтеза речи - особенно с Coqui.***"
      ],
      "metadata": {
        "id": "-YcQuyP0bWqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Запустить перед началом работы"
      ],
      "metadata": {
        "id": "mfkRU81vby8Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w4OxjRHaeDt"
      },
      "outputs": [],
      "source": [
        "#!pip install moviepy\n",
        "!pip install pydub\n",
        "!pip install ffmpeg-python\n",
        "!pip install iso639\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip, concatenate_videoclips\n",
        "from moviepy.video.fx.accel_decel import accel_decel\n",
        "import re\n",
        "from IPython.display import clear_output, Audio, display\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "from google.colab import files\n",
        "import subprocess\n",
        "import ffmpeg\n",
        "import torch\n",
        "import locale # для восстановления кодировки\n",
        "import iso639 # для кодов языков\n",
        "import cv2\n",
        "\n",
        "times = [] # для корректировки субтитров в конце\n",
        "\n",
        "\n",
        "def str_to_time(s):\n",
        "  return int(s[6:8]) + 60 * int(s[3:5]) + 3600 * int(s[:2]) + float('0.' + s[9:12])\n",
        "\n",
        "\n",
        "def time_to_str(time):\n",
        "  hours = int(time // 3600)\n",
        "  minutes = int((time - 3600 * hours) // 60)\n",
        "  seconds = time - 60 * minutes\n",
        "  str_sec = str(round(seconds, 3)).replace('.', ',')\n",
        "  return str(hours).zfill(2) + ':' + str(minutes).zfill(2) + ':' + str_sec[:str_sec.find(',')].zfill(2) + ',' + str_sec[str_sec.find(',') + 1:].ljust(3, '0')\n",
        "\n",
        "\n",
        "def extract_number(s):\n",
        "  match = re.search(r'\\d+', s) # регулярное выражение \\d+ означает \"одна или более цифр подряд\"\n",
        "  if match:\n",
        "    return int(match.group())\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "def add_pause(old_path, aud_path, dur):\n",
        "  # генерация тишины (в миллисекундах)\n",
        "  silence = AudioSegment.silent(duration = dur * 1000)\n",
        "  audio = AudioSegment.from_file(old_path)\n",
        "  audio += silence\n",
        "  audio.export(aud_path, format = \"wav\")\n",
        "\n",
        "\n",
        "def speedup(path, speed):\n",
        "  filter = \"atempo=\" + str(speed)\n",
        "  command = \"ffmpeg -i \" + path + \" -filter:a \" + filter + \" /content/changed.wav\"\n",
        "  process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  output, error = process.communicate()\n",
        "  os.remove(path)\n",
        "  os.rename(\"/content/changed.wav\", path)\n",
        "\n",
        "\n",
        "def check_duration(old_path, aud_path, start, end, slow_aud, limit):\n",
        "  duration = (end - start) * 1000 # в миллисекундах\n",
        "  # измеряем продолжительность синтезированного фрагмента\n",
        "  audio = AudioSegment.from_file(path)\n",
        "  if len(audio) != duration: # если аудио получилось больше или меньше требуемой продолжительности\n",
        "    # нужно его ускорить и замедлить или добавить паузу (в зависимости от режима)\n",
        "    coef = len(audio) / duration # коэффициент растяжения или сжатия\n",
        "    if coef < 1:\n",
        "      if not slow_aud: # не замедляем аудио\n",
        "        add_pause(old_path, aud_path, (duration - len(audio)) / 1000)\n",
        "      else:\n",
        "        if limit:\n",
        "          if coef >= 0.9: # замедление будет выполнено, только если аудио не станет медленнее этого значения\n",
        "            !cp $old_path $aud_path\n",
        "            speedup(aud_path, coef)\n",
        "        else:\n",
        "          !cp $old_path $aud_path\n",
        "          speedup(aud_path, coef)\n",
        "    else:\n",
        "      # ограничение на ускорение в случае с аудио не накладываем, т. к. в видеофрагмент важно уложиться\n",
        "      !cp $old_path $aud_path\n",
        "      speedup(aud_path, coef)\n",
        "  else: # Всё равно копируем в новую папку\n",
        "    !cp $old_path $aud_path\n",
        "\n",
        "\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "\n",
        "\n",
        "def video_duration(filename):\n",
        "  video = cv2.VideoCapture(filename)\n",
        "\n",
        "  fps = video.get(cv2.CAP_PROP_FPS)\n",
        "  frame_count = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "  duration = frame_count / fps\n",
        "\n",
        "  video.release()\n",
        "\n",
        "  return duration\n",
        "\n",
        "\n",
        "def check_vid_duration(aud_path, vid_path, limit):\n",
        "  # получение продолжительности видео\n",
        "  audio = AudioSegment.from_file(aud_path)\n",
        "  video = VideoFileClip(vid_path).without_audio()\n",
        "  times.append(len(audio) / 1000)\n",
        "  if abs(len(audio) / 1000 - video.duration) > 0.05: # аудио короче или длиннее видео на более чем 50 мс\n",
        "    coef = round(video.duration / (len(audio) / 1000), 3)\n",
        "    if limit:\n",
        "      # проверка коэффициента, замедление или усорение будет выполнено, только если коэффициент в данных пределах\n",
        "      if coef <= 1.1 and coef >= 0.9:\n",
        "        video = accel_decel(video, video.duration / coef, abruptness = 0)\n",
        "        os.remove(vid_path)\n",
        "        video.write_videofile(vid_path, threads = 4)\n",
        "      else: # иначе работа с самим аудио\n",
        "        if coef > 1: # если видео собирались ускорить, к аудио добавляем паузу\n",
        "          pause_len = video.duration - (len(audio) / 1000) # в с\n",
        "          add_pause(aud_path, aud_path, pause_len)\n",
        "        else: # если видео собирались замедлить, то ускоряем аудио\n",
        "          speedup(aud_path, 1 / coef)\n",
        "          audio = AudioSegment.from_file(aud_path)\n",
        "          times.pop()\n",
        "          times.append(len(audio) / 1000)\n",
        "    else:\n",
        "      video = accel_decel(video, video.duration / coef, abruptness = 0)\n",
        "      os.remove(vid_path)\n",
        "      video.write_videofile(vid_path, threads = 4)\n",
        "\n",
        "\n",
        "def form_boundary(time, clone_path):\n",
        "  ok = True\n",
        "  pos = time.find(':')\n",
        "  if pos != -1:\n",
        "    buf = time[: pos]\n",
        "    if not (len(buf) > 0 and len(buf) < 3 and buf.isdigit() and int(buf) > 0):\n",
        "      ok = False\n",
        "    buf = time[pos + 1 :]\n",
        "    if not (len(buf) > 0 and len(buf) < 3 and buf.isdigit() and int(buf) > 0):\n",
        "      ok = False\n",
        "    if ok:\n",
        "      buf = int(time[: pos]) * 60 + int(time[pos + 1 :])\n",
        "      dur = len(AudioSegment.from_file(clone_path))\n",
        "      if buf > dur: # если больше продолжительности видео\n",
        "        ok = False\n",
        "        print(\"Введённое вами время превышает продолжительность аудиофайла!\")\n",
        "  else:\n",
        "    ok = False\n",
        "\n",
        "  return ok, buf\n",
        "\n",
        "\n",
        "def choice_silero_model(lang, gender='female'):\n",
        "  ver = '3-4'\n",
        "  voice = None # для тех языков, где нет выбора голосов\n",
        "  indic_languages = ['bengali', 'gujarati', 'hindi', 'kannada', 'malayalam',\n",
        "                     'manipuri', 'rajasthani', 'tamil', 'telugu']\n",
        "\n",
        "  if lang == 'russian':\n",
        "    model_id = 'v4_ru'\n",
        "  elif lang == 'english':\n",
        "    model_id = 'v3_en'\n",
        "  elif lang == 'german':\n",
        "    model_id = 'v3_de'\n",
        "  elif lang == 'spanish':\n",
        "    model_id = 'v3_es'\n",
        "  elif lang == 'french':\n",
        "    model_id = 'v3_fr'\n",
        "  elif lang == 'bashkir':\n",
        "    model_id = 'aigul_v2'\n",
        "    ver = '2'\n",
        "  elif lang == 'kalmyk':\n",
        "    model_id = 'v3_xal'\n",
        "  elif lang == 'tatar':\n",
        "    model_id = 'v3_tt'\n",
        "    voice = 'dilyara'\n",
        "  elif lang == 'uzbek':\n",
        "    model_id = 'v4_uz'\n",
        "    voice = 'dilnavoz'\n",
        "  elif lang == 'ukrainian':\n",
        "    model_id = 'v4_ua'\n",
        "  # индийские языки\n",
        "  elif lang in indic_languages:\n",
        "    model_id = 'v4_indic'\n",
        "    if lang != 'manipuri':\n",
        "      voice = language + '_' + gender\n",
        "    else:\n",
        "      voice = 'manipuri_female'\n",
        "  # кириллические языки\n",
        "  else:\n",
        "    model_id = 'v4_cyrillic'\n",
        "\n",
        "  return model_id, voice, ver\n",
        "\n",
        "\n",
        "# Функция синтеза для Yandex-Speechkit\n",
        "def synthesize(text, export_path, voice, role):\n",
        "  model = model_repository.synthesis_model()\n",
        "\n",
        "  # настройки синтеза\n",
        "  model.voice = voice\n",
        "  model.role = role\n",
        "\n",
        "  # синтез речи и создание аудио с результатом\n",
        "  result = model.synthesize(text, raw_format = False)\n",
        "  result.export(export_path, 'wav')\n",
        "\n",
        "\n",
        "# Проверка на то, что файл имеет необходимую структуру\n",
        "def check_txtfile(filename):\n",
        "  txtfile = open(filename, \"r\", encoding = \"utf-8\")\n",
        "  lines = [''] + txtfile.read().split('\\n')\n",
        "  txtfile.close()\n",
        "  ok = True\n",
        "  if (len(lines) % 4 == 0):\n",
        "    for i in range(0, len(lines), 4):\n",
        "      if lines[i]:\n",
        "        ok = False\n",
        "      if not re.match(r'^\\d+$', lines[i + 1]):\n",
        "        ok = False\n",
        "      if not re.match(r'\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}', lines[i + 2]):\n",
        "        ok = False\n",
        "      if not lines[i + 3]:\n",
        "        ok = False\n",
        "  else:\n",
        "    ok = False\n",
        "  return ok\n",
        "\n",
        "\n",
        "def silero_save(audio, path, sample_rate):\n",
        "  # Преобразуем тензор в массив NumPy\n",
        "  audio_np = audio.numpy()\n",
        "  # Нормализуем значения массива NumPy к диапазону [-1, 1]\n",
        "  audio_np = np.clip(audio_np, -1, 1)\n",
        "  # Масштабируем значения к диапазону int16 для сохранения в формате WAV\n",
        "  audio_np_int16 = np.int16(audio_np * 32767)\n",
        "  # Сохраняем массив NumPy как файл WAV\n",
        "  wavfile.write(path, sample_rate, audio_np_int16)\n",
        "\n",
        "\n",
        "# переменные для регулирования процесса загрузки видео и/или аудио\n",
        "yt_downloaded = False\n",
        "gd_mounted = False\n",
        "gtts_installed = False\n",
        "edge_installed = False\n",
        "silero_installed = False\n",
        "yandex_installed = False\n",
        "coqui_installed = False\n",
        "vm_crtd = False\n",
        "\n",
        "path_to_text = '/content/subtitles.srt'\n",
        "path_to_video = '/content/vid.mp4'\n",
        "clone_sample = '/content/clone_voice.wav'\n",
        "path_to_init = '/content/synthesized1'\n",
        "path_to_synth = '/content/synthesized'\n",
        "\n",
        "yandex_languages = {'german' : [{'name': 'lea', 'gender' : 'female', 'roles' : []}],\n",
        "                    'english' : [{'name': 'john', 'gender' : 'male', 'roles' : []}],\n",
        "                    'hebrew' : [{'name': 'naomi', 'gender' : 'female', 'roles' : ['modern', 'classic']}],\n",
        "                    'kazakh' : [{'name': 'amira', 'gender' : 'female', 'roles' : []},\n",
        "                                  {'name': 'madi', 'gender' : 'male', 'roles' : []}],\n",
        "                    'russian' : [{'name': 'alena', 'gender' : 'female', 'roles' : ['neutral', 'good']},\n",
        "                                  {'name': 'filipp', 'gender' : 'male', 'roles' : []},\n",
        "                                  {'name': 'ermil', 'gender' : 'male', 'roles' : ['neutral', 'good']},\n",
        "                                  {'name': 'jane', 'gender' : 'female', 'roles' : ['neutral', 'good', 'evil']},\n",
        "                                  {'name': 'madirus', 'gender' : 'male', 'roles' : []},\n",
        "                                  {'name': 'omazh', 'gender' : 'female', 'roles' : ['neutral', 'evil']},\n",
        "                                  {'name': 'zahar', 'gender' : 'male', 'roles' : ['neutral', 'good']},\n",
        "                                  {'name': 'dasha', 'gender' : 'female', 'roles' : ['neutral', 'good', 'friendly']},\n",
        "                                  {'name': 'julia', 'gender' : 'female', 'roles' : ['neutral', 'strict']},\n",
        "                                  {'name': 'lera', 'gender' : 'female', 'roles' : ['neutral', 'friendly']},\n",
        "                                  {'name': 'marina', 'gender' : 'female', 'roles' : ['neutral', 'whisper', 'strict']},\n",
        "                                  {'name': 'alexander', 'gender' : 'male', 'roles' : ['neutral', 'good']},\n",
        "                                  {'name': 'kirill', 'gender' : 'male', 'roles' : ['neutral', 'strict', 'good']},\n",
        "                                  {'name': 'anton', 'gender' : 'male', 'roles' : ['neutral', 'good']}],\n",
        "                    'uzbek' : [{'name': 'nigora', 'gender' : 'female', 'roles' : []}]\n",
        "                    }\n",
        "xtts_languages = ['english', 'spanish', 'french', 'german', 'italian', 'portuguese', 'polish', 'turkish', 'russian', 'dutch', 'czech', 'arabic', 'chinese', 'japanese', 'hungarian', 'korean']\n",
        "silero_languages = ['Russian', 'Ukrainian', 'Uzbek', 'Avar', 'Bashkir', 'Bulgarian', 'Chechen',\n",
        "                    'Chuvash', 'Erzya', 'Kalmyk', 'Karachay-Balkar', 'Kazakh', 'Khakas',\n",
        "                    'Komi-Ziryan', 'Lezghian', 'Mari', 'Mari High', 'Nogai', 'Ossetic', 'Tatar',\n",
        "                    'Tuvinian', 'Udmurt', 'Yakut', 'Hindi', 'Malayalam', 'Manipuri', 'Bengali',\n",
        "                    'Rajasthani', 'Tamil', 'Telugu', 'Gujarati', 'Kannada', 'English', 'German',\n",
        "                    'Spanish', 'French']\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка текста, видео и/или образца голоса"
      ],
      "metadata": {
        "id": "PjVGysqseJnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Загрузка текста (файла со структурой SRT)\n",
        "\n",
        "# @markdown Выберите метод загрузки и укажите путь к файлу, если привязываете Google Диск:\n",
        "# @markdown ### Способ загрузки\n",
        "upload_method = \"С устройства\" #@param [\"С устройства\", \"Путь к файлу Google Drive\"]\n",
        "#@markdown <font color=\"orange\"> Примечания и советы:\n",
        "\n",
        "#@markdown <font color=\"orange\"> ``1. При выборе загрузки с устройства нужно будет нажать на кнопку в выходных данных и выбрать файл с устройства.``\n",
        "\n",
        "#@markdown <font color=\"orange\"> ``2. Обратите внимание: при выборе способа, связанного с Google Диском, система попросит вас дать разрешение на доступ к вашему Google Drive. Затем он будет смонтирован в файловую систему. После этого укажите путь к файлу в соответствующем поле.``\n",
        "\n",
        "#@markdown ``Введите полный путь к видео на вашем Google Диске (для варианта с загрузкой с Google Drive) `` 👇\n",
        "path_google_drive = '/content/drive/MyDrive/path_to_subs' #@param {type:\"string\"}\n",
        "\n",
        "# Удаление файла, если такой уже был в ФС прежде\n",
        "if os.path.isfile(path_to_text):\n",
        "    os.remove(path_to_text)\n",
        "\n",
        "path_to_text = '/content/subtitles.srt' # путь к файлу по умолчанию\n",
        "\n",
        "# Видеофайл загружается разными способами\n",
        "if upload_method == \"С устройства\":\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    if not (filename.endswith('.srt') or filename.endswith('.txt')):\n",
        "      print(\"Файл должен иметь расширение SRT или TXT!\")\n",
        "      raise SystemExit(0)\n",
        "    if '/content/' + filename != path_to_text:\n",
        "      os.rename(filename, path_to_text) # переименование загруженного файла\n",
        "else:\n",
        "  if not gd_mounted:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\") # монтирование Google Диска при первом запуске\n",
        "    gd_mounted = True\n",
        "  if not os.path.isfile(path_google_drive): # если файл не найден\n",
        "    print(\"ERROR: File not found!\")\n",
        "    raise SystemExit(0)\n",
        "  if not (path_google_drive.endswith('.srt') or path_google_drive.endswith('.srt')):\n",
        "    print(\"Файл должен иметь расширение SRT или TXT!\")\n",
        "    raise SystemExit(0)\n",
        "  !cp $path_google_drive $path_to_text # копирование файла с Google Диска\n",
        "\n",
        "# Проверка на то, что файл имеет необходимую структуру\n",
        "if check_txtfile(path_to_text):\n",
        "  clear_output()\n",
        "else:\n",
        "  print('Неверная структура выбранного файла!')"
      ],
      "metadata": {
        "id": "0Hi7sqmMFdQi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Загрузка видео\n",
        "# @markdown Выберите метод загрузки и укажите путь к файлу, если привязываете Google Диск:\n",
        "# @markdown ### Способ загрузки\n",
        "upload_method = \"С устройства\" #@param [\"С устройства\", \"По ссылке с YouTube\", \"Путь к файлу Google Drive\"]\n",
        "#@markdown <font color=\"orange\"> Примечания и советы:\n",
        "\n",
        "#@markdown <font color=\"orange\"> ``1. При выборе загрузки с устройства нужно будет нажать на кнопку в выходных данных и выбрать файл с устройства.``\n",
        "\n",
        "#@markdown <font color=\"orange\"> ``2. Для загрузки с YouTube укажите ссылку в соответствующее поле.``\n",
        "\n",
        "#@markdown <font color=\"orange\"> ``3. Обратите внимание: при выборе способа, связанного с Google Диском, система попросит вас дать разрешение на доступ к вашему Google Drive. Затем он будет смонтирован в файловую систему. После этого укажите путь к файлу в соответствующем поле.``\n",
        "\n",
        "#@markdown ``Вставьте ссылку на видеоролик с платформы YouTube в требуемом формате `` 👇\n",
        "youtube_url = 'https://www.youtube.com/watch?v=YOUTUBE_ID' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ``Введите полный путь к видео на вашем Google Диске (для варианта с загрузкой с Google Drive) `` 👇\n",
        "path_google_drive = '/content/drive/MyDrive/path_to_vid' #@param {type:\"string\"}\n",
        "\n",
        "from urllib import parse as urlparse\n",
        "\n",
        "# Удаление файла, если такой уже был в ФС прежде\n",
        "if os.path.isfile(path_to_video):\n",
        "    os.remove(path_to_video)\n",
        "\n",
        "path_to_video = '/content/vid.mp4' # путь к видео по умолчанию\n",
        "\n",
        "# Видеофайл загружается разными способами\n",
        "if upload_method == \"С устройства\":\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    if '/content/' + filename != path_to_video:\n",
        "      os.rename(filename, path_to_video) # переименование загруженного файла\n",
        "elif upload_method == \"По ссылке с YouTube\":\n",
        "  if not yt_downloaded:\n",
        "    !pip install yt-dlp # установка при первом запуске\n",
        "    yt_downloaded = True\n",
        "  url_data = urlparse.urlparse(youtube_url)\n",
        "  query = urlparse.parse_qs(url_data.query)\n",
        "  YOUTUBE_ID = query[\"v\"][0]\n",
        "  # Загрузка видео с YouTube\n",
        "  !yt-dlp -f \"bestvideo[ext=mp4]+bestaudio[ext=wav]/best[ext=mp4]/best\" --output \"/content/vid.%(ext)s\" https://www.youtube.com/watch?v=$YOUTUBE_ID\n",
        "  # Запоминаем путь к файлу\n",
        "  for file in os.listdir('/content'):\n",
        "    if file.startswith('vid'):\n",
        "        path_to_video = os.path.join(directory, file)\n",
        "else:\n",
        "  if not gd_mounted:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\") # монтирование Google Диска при первом запуске\n",
        "    gd_mounted = True\n",
        "  if not os.path.isfile(path_google_drive): # если файл не найден\n",
        "      print(\"ERROR: File not found!\")\n",
        "      raise SystemExit(0)\n",
        "  !cp $path_google_drive $path_to_video # копирование файла с Google Диска\n",
        "\n",
        "clear_output() # очистка выходных данных"
      ],
      "metadata": {
        "cellView": "form",
        "id": "BaVR6Kd0eKwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Образец голоса для клонирования\n",
        "# @markdown Клонирование голоса может понадобиться, если для вас важно максимально приближенное звучание голоса к оригиналу.\n",
        "\n",
        "# @markdown Также это необходимо для XTTSv2 из Coqui TTS\n",
        "\n",
        "# @markdown ### Выберите метод получения образца голоса для клонирования\n",
        "clone_method = \"С устройства\" #@param [\"С устройства\", \"Путь к файлу Google Drive\", \"Фрагмент из видео\"]\n",
        "\n",
        "#@markdown <font color=\"orange\"> Примечания и советы:\n",
        "\n",
        "#@markdown <font color=\"orange\"> ``1. При выборе загрузки с устройства нужно будет нажать на кнопку в выходных данных и выбрать файл с устройства.``\n",
        "\n",
        "#@markdown <font color=\"orange\"> ``2. Обратите внимание: при выборе способа, связанного с Google Диском, система попросит вас дать разрешение на доступ к вашему Google Drive. Затем он будет смонтирован в файловую систему. После этого укажите путь к файлу в соответствующем поле.``\n",
        "\n",
        "#@markdown <font color=\"orange\"> ``3. Для извлечения образца из видео укажите в соответствующее поле временной интервал.``\n",
        "\n",
        "#@markdown <font color=\"red\"> ``Если необходимо обрезать загруженный аудиофайл, также укажите интервал в тех же полях.``\n",
        "\n",
        "#@markdown ``Введите полный путь к видео на вашем Google Диске (для варианта с загрузкой с Google Drive) `` 👇\n",
        "path_google_drive = '/content/drive/MyDrive/path_to_aud' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ``Введите начало и конец промежутка в формате <минуты>:<секунды> или 0, если не задаёте какую-то или обе границы`` 👇\n",
        "start_str = \"0\" #@param {type:\"string\"}\n",
        "end_str = \"0\" #@param {type:\"string\"}\n",
        "\n",
        "# Удаление файла, если такой уже был в ФС прежде\n",
        "if os.path.isfile(clone_sample):\n",
        "    os.remove(clone_sample)\n",
        "\n",
        "clone_sample = '/content/clone_voice.wav' # путь к образцу по умолчанию\n",
        "ok_s = False\n",
        "ok_e = False\n",
        "\n",
        "# Разные способы получения образца голоса\n",
        "if clone_method == \"С устройства\":\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    # переименование загруженного файла\n",
        "    if filename.endswith('.wav'):\n",
        "      if '/content/' + filename != clone_sample:\n",
        "        os.rename(filename, clone_sample)\n",
        "    elif filename.endswith('.mp3'):\n",
        "      if '/content/' + filename != '/content/clone_voice.mp3':\n",
        "        os.rename(filename, '/content/clone_voice.mp3')\n",
        "      clone_sample = '/content/clone_voice.mp3'\n",
        "  clear_output() # очистка выходных данных\n",
        "elif clone_method == \"Путь к файлу Google Drive\":\n",
        "  if not gd_mounted:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\") # монтирование Google Диска при первом запуске\n",
        "    gd_mounted = True\n",
        "  if not os.path.isfile(path_google_drive): # если файл не найден\n",
        "      print(\"ERROR: File not found!\")\n",
        "      raise SystemExit(0)\n",
        "  if path_google_drive.endswith('wav'):\n",
        "    !cp $path_google_drive $clone_sample # копирование файла с Google Диска\n",
        "  elif path_google_drive.endswith('mp3'):\n",
        "    !cp $path_google_drive /content/clone_voice.mp3\n",
        "    clone_sample = '/content/clone_voice.mp3'\n",
        "  clear_output()\n",
        "else:\n",
        "  if os.path.isfile(path_to_video):\n",
        "    # извлечение аудиодорожки из видео\n",
        "    video = VideoFileClip(path_to_video)\n",
        "    video.audio.write_audiofile('/content/clone_voice.wav')\n",
        "    clear_output()\n",
        "  else:\n",
        "    print('Вы не загрузили видео!')\n",
        "    raise SystemExit(0)\n",
        "\n",
        "# обрезание любого аудиофайла\n",
        "if start_str != '0':\n",
        "  ok_s, start = form_boundary(start_str) # формирование времени начала в секундах\n",
        "else:\n",
        "  start = 0\n",
        "  ok_s = True\n",
        "if end_str != '0':\n",
        "  ok_e, end = form_boundary(end_str) # формирование времени окончания в секундах\n",
        "else:\n",
        "  end = 0\n",
        "  ok_e = True\n",
        "\n",
        "if ok_s and ok_e:\n",
        "  # обрезаем аудио (AudioSegment работает с миллисекундами)\n",
        "  old_audio = AudioSegment.from_file(clone_sample)\n",
        "  if start != 0 and end != 0:\n",
        "    extract = old_audio[start * 1000:end * 1000]\n",
        "  elif start == 0:\n",
        "    extract = old_audio[:end * 1000]\n",
        "  elif end == 0:\n",
        "    extract = old_audio[start * 1000:]\n",
        "  else:\n",
        "    extract = old_audio\n",
        "  # сохраняем\n",
        "  !rm $clone_sample\n",
        "  extract.export(clone_sample, format = clone_sample[-3:])\n",
        "\n",
        "  clear_output()\n",
        "else:\n",
        "  print(\"Вы неправильно ввели значения! Попробуйте ещё раз. Пример в примечании.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9Di1xxj5fJtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Дополнительно: загрузка zip-архива с синтезированными фразами\n",
        "\n",
        "# @markdown Сформируйте zip-архив, содержащий пронумерованные по порядку wav-файлы, и нажмите на кнопку загрузки, которая появится здесь.\n",
        "\n",
        "!rm -rf /content/synthesized1\n",
        "\n",
        "# Загрузка zip-архива с wav-файлами\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Распаковка архива\n",
        "for fn in uploaded.keys():\n",
        "  !unzip {fn} -d /content/speech_downloaded\n",
        "\n",
        "# Копирование всех файлов wav в буферную папку\n",
        "buf_fold = '/content/buffer_folder'\n",
        "os.makedirs(buf_fold, exist_ok=True)\n",
        "\n",
        "for root, dirs, filess in os.walk('/content/speech_downloaded'):\n",
        "  for file in filess:\n",
        "    if file.endswith('.wav'):\n",
        "     os.rename(os.path.join(root, file), os.path.join(buf_fold, file))\n",
        "\n",
        "# Удаление распакованной папки\n",
        "!rm -rf /content/speech_downloaded\n",
        "\n",
        "# Переименование буферной папки\n",
        "os.rename(buf_fold, '/content/synthesized1')\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EanBcqwdCepW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Дополнительно: загрузка zip-архивов с нарезанными фрагментами видео\n",
        "\n",
        "# @markdown Сформируйте 2 zip-архива, содержащие пронумерованные по порядку mp4-файлы, и нажмите на кнопку загрузки, которая появится здесь.\n",
        "\n",
        "# @markdown Заметьте, что первый файл должен называться fragments.zip, а второй - int_fragms.zip.\n",
        "\n",
        "# @markdown Первый содержит фрагменты, в которых присутствует речь, а второй - промежуточные.\n",
        "\n",
        "!rm -rf /content/fragments\n",
        "!rm -rf /content/int_fragms\n",
        "\n",
        "# Загрузка zip-архивов с mp4-файлами\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Распаковка архива\n",
        "for fn in uploaded.keys():\n",
        "  if fn == 'fragments.zip':\n",
        "    !unzip {fn} -d /content/fr\n",
        "  elif fn == 'int_fragms.zip':\n",
        "    !unzip {fn} -d /content/ifr\n",
        "  else:\n",
        "    print('К сожалению, вы назвали один из файлов неправильно. Перепроверьте.')\n",
        "    !rm -rf /content/fr\n",
        "    !rm -rf /content/ifr\n",
        "    raise SystemExit(0)\n",
        "\n",
        "# Копирование всех файлов wav в буферную папку\n",
        "buf_fold1 = '/content/buffer_folder1'\n",
        "buf_fold2 = '/content/buffer_folder2'\n",
        "os.makedirs(buf_fold1, exist_ok=True)\n",
        "os.makedirs(buf_fold2, exist_ok=True)\n",
        "\n",
        "for root, dirs, filenames in os.walk('/content/fr'):\n",
        "  for file in filenames:\n",
        "    if file.endswith('.mp4'):\n",
        "     os.rename(os.path.join(root, file), os.path.join(buf_fold1, file))\n",
        "for root, dirs, filenames in os.walk('/content/ifr'):\n",
        "  for file in filenames:\n",
        "    if file.endswith('.mp4'):\n",
        "     os.rename(os.path.join(root, file), os.path.join(buf_fold2, file))\n",
        "\n",
        "# Удаление распакованных папок\n",
        "!rm -rf /content/fr\n",
        "!rm -rf /content/ifr\n",
        "\n",
        "# Переименование буферных папок\n",
        "os.rename(buf_fold1, '/content/fragments')\n",
        "os.rename(buf_fold2, '/content/int_fragms')\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yuUW-npyJirM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Синтез речи"
      ],
      "metadata": {
        "id": "N9MhhhPXFFgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Синтез речи\n",
        "# @markdown <font color=\"green\"> *Чтобы получить помощь в выборе инструмента и голосов, а также протестировать голоса, воспользуйтесь ячейками ниже.*\n",
        "\n",
        "# @markdown Выберите инструмент для синтеза:\n",
        "tool = 'Coqui TTS' # @param [\"Yandex SpeechKit\", \"Coqui TTS\", \"gTTS\", \"Microsoft Edge TTS\", \"Silero Models\"]\n",
        "# @markdown Введите язык (на английском), на котором будет производиться синтез:\n",
        "language = 'english' # @param {type: \"string\"}\n",
        "if language and language.isalpha():\n",
        "  language = language.lower()\n",
        "  lang_capital = language[0].upper() + language[1 :]\n",
        "else:\n",
        "  print('Пожалуйста, введите язык синтеза корректно.')\n",
        "  raise SystemExit(0)\n",
        "# @markdown Собираетесь ли вы клонировать голос? (для повышения сходства с оригиналом)\n",
        "cloning = False  # @param {type: \"boolean\"}\n",
        "# @markdown Какой голос предпочтительнее?\n",
        "gender = \"мужской\"  # @param [\"мужской\", \"женский\"]\n",
        "# @markdown Нужно ли сразу замедлять или ускорять синтезированные фразы? Введите 1, если не надо, и скорость, если надо.\n",
        "speed_str = \"1\" #@param {type: \"string\"}\n",
        "try:\n",
        "  speed = float(speed_str)\n",
        "  if speed <= 0:\n",
        "    print('Скорость не может быть отрицательным значением!')\n",
        "    raise SystemExit(0)\n",
        "except ValueError:\n",
        "  print('Вы ввели некорректное значение скорости!')\n",
        "  SystemExit(0)\n",
        "\n",
        "# @markdown <font color=\"red\"> <font size=4> <center> Дополнительные настройки\n",
        "\n",
        "# @markdown <font color=\"orange\"> Выберите голос (для Yandex, Edge и Silero):\n",
        "voice = \"john\" # @param {type: \"string\"}\n",
        "#@markdown <font color=\"lightblue\"> Выберите амплуа голоса (или \"нет\", если его у модели нет) - для Yandex:\n",
        "role = \"нет\" # @param [\"нет\", \"neutral\", \"good\", \"evil\", \"friendly\", \"strict\", \"whisper\", \"modern\", \"classic\"]\n",
        "# @markdown <font color=\"purple\"> Выберите модель (для Coqui TTS):\n",
        "model_name = \"xtts_v2\" #@param [\"xtts_v2\", \"tacotron2-DDC_ph (only english)\"]\n",
        "# @markdown <font color=\"pink\"> Введите ваш ключ API для Yandex SpeechKit:\n",
        "API_key = \"\" #@param {type: \"string\"}\n",
        "# @markdown <font color=\"green\"> Скачать zip-архив с синтезированной речью?\n",
        "download_file = False #@param {type: \"boolean\"}\n",
        "\n",
        "\n",
        "xtts_inst = False\n",
        "taco_inst = False\n",
        "path_to_init = '/content/synthesized1' # синтезированные фразы до добавления к ним пауз\n",
        "!mkdir /content/synthesized1\n",
        "\n",
        "# проверка на то, что файл был загружен\n",
        "if os.path.isfile(path_to_text):\n",
        "  # Получить устройство\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "  # ЕСЛИ ВЫБРАЛИ YANDEX\n",
        "  if tool == \"Yandex-Speechkit\":\n",
        "    # Проверки входных данных\n",
        "    if language not in yandex_languages:\n",
        "      print('Данный язык не поддерживается Yandex SpeechKit!')\n",
        "      raise SystemExit(0)\n",
        "    if voice not in [item['name'] for item in yandex_languages[language]]:\n",
        "      print('В Yandex SpeechKit нет такого голоса! Посмотрите доступные по ссылке в ячейке ниже.')\n",
        "      raise SystemExit(0)\n",
        "    gender = 'male' if gender == 'мужской' else 'female'\n",
        "    if not cloning and gender != [item['gender'] for item in yandex_languages[language] if item['name'] == voice][0]:\n",
        "      print('Этот голос имеет другой пол. Попробуйте воспользоваться ячейкой ниже, чтобы выбрать подходящий голос.')\n",
        "      raise SystemExit(0)\n",
        "    if not API_key:\n",
        "      print('Для синтеза речи с помощью Yandex SpeechKit необходим ключ API!')\n",
        "      raise SystemExit(0)\n",
        "\n",
        "    if not yandex_installed:\n",
        "      # установка\n",
        "      !pip install yandex-speechkit\n",
        "      from speechkit import model_repository, configure_credentials, creds\n",
        "\n",
        "      # Аутентификация через API-ключ.\n",
        "      configure_credentials(\n",
        "        yandex_credentials=creds.YandexCredentials(\n",
        "            api_key = API_key\n",
        "        )\n",
        "      )\n",
        "      yandex_installed = True\n",
        "\n",
        "    # синтез речи с помощью Yandex SpeechKit\n",
        "    for i in range(0, len(lines), 4):\n",
        "      export_path = path_to_init + '/' + str(int(i / 4)) + '.wav'\n",
        "      synthesize(lines[i+3], export_path) # синтез фразы\n",
        "      if speed != 1:\n",
        "        speedup(export_path, speed)\n",
        "\n",
        "  # ЕСЛИ ВЫБРАЛИ COQUI\n",
        "  elif tool == \"Coqui TTS\":\n",
        "    if model_name == \"xtts_v2\" and not os.path.isfile(clone_sample):\n",
        "      print('XTTSv2 обязательно нужен файл для клонирования голоса, но вы не загрузили образец! Вернитесь к предыдущему разделу.')\n",
        "      raise SystemExit(0)\n",
        "    if model_name == \"xtts_v2\" and language not in xtts_languages:\n",
        "      print('Данный язык не поддерживается XTTSv2!')\n",
        "      raise SystemExit(0)\n",
        "    if model_name == \"tacotron2-DDC_ph (only english)\" and language != \"english\":\n",
        "      print('tacotron2-DDC_ph поддерживает только английский язык!')\n",
        "      raise SystemExit(0)\n",
        "\n",
        "    if not coqui_installed:\n",
        "      # установка TTS\n",
        "      !pip install TTS\n",
        "      from TTS.api import TTS\n",
        "      coqui_installed = True\n",
        "    if model_name == \"xtts_v2\":\n",
        "      if not xtts_inst:\n",
        "        # загрузка многоязычной модели\n",
        "        model_str = \"tts_models/multilingual/multi-dataset/\" + model_name\n",
        "        tts = TTS(model_str).to(device)\n",
        "        xtts_inst = True\n",
        "      # синтез речи с помощью XTTSv2\n",
        "      lang_code = iso639.to_iso639_1(lang_capital)\n",
        "      for i in range(0, len(lines), 4):\n",
        "        export_path = path_to_init + '/' + str(int(i / 4)) + '.wav'\n",
        "        # синтез фразы\n",
        "        tts.tts_to_file(text = lines[i+3], file_path = export_path,\n",
        "                        speaker_wav = [clone_sample],\n",
        "                        language = lang_code)\n",
        "        if speed != 1:\n",
        "          speedup(export_path, speed)\n",
        "    else: # tacotron2-DDC_ph\n",
        "      if not taco_inst:\n",
        "        model_str = \"tts_models/en/ljspeech/\" + model_name\n",
        "        tts = TTS(model_str).to(device)\n",
        "        taco_inst = True\n",
        "      # синтез речи с помощью tacotron2-DDC_ph\n",
        "      for i in range(0, len(lines), 4):\n",
        "        export_path = path_to_init + '/' + str(int(i / 4)) + '.wav'\n",
        "        # синтез фразы\n",
        "        tts.tts_to_file(text = lines[i+3], file_path = export_path)\n",
        "        if speed != 1:\n",
        "          speedup(export_path, speed)\n",
        "\n",
        "    # восстановление кодировки в среде (UTF-8)\n",
        "    locale.getpreferredencoding = getpreferredencoding\n",
        "\n",
        "  # ЕСЛИ ВЫБРАЛИ GTTS\n",
        "  elif tool == \"gTTS\":\n",
        "    if not gtts_installed:\n",
        "      # установка, если не было установлено\n",
        "      !pip install gTTS\n",
        "      from gtts import gTTS, lang\n",
        "      gtts_installed = True\n",
        "    # проверка наличия языков\n",
        "    lang_av_ct = 0\n",
        "    for val in lang.tts_langs().values():\n",
        "      if lang_capital in val:\n",
        "        lang_av_ct += 1\n",
        "    if lang_av_ct > 1:\n",
        "      print('Найдено несколько подходящих языков:')\n",
        "      lang_arr = [val for val in lang.tts_langs().values() if lang_capital in val]\n",
        "      print(', '.join(lang_arr))\n",
        "      while True:\n",
        "        try:\n",
        "          lang_num = int(input('Выберите один из них (введите номер от 1 до ', lang_av_ct, '):'))\n",
        "          if 1 <= lang_num <= lang_av_ct:  # проверка на то, что число находится в нужном диапазоне\n",
        "              break\n",
        "          else:\n",
        "              print(\"Вы ввели номер неправильно. Попробуйте снова.\")\n",
        "        except ValueError:\n",
        "          print(\"Вы неправильно ввели номер, попробуйте снова.\")\n",
        "      lang_code = {v: k for k, v in lang.tts_langs().items()}.get(lang_arr[lang_num-1]) # инвертирование словаря\n",
        "    elif not lang_av_ct:\n",
        "      print('gTTS не поддерживает данный язык!')\n",
        "      raise SystemExit(0)\n",
        "    else:\n",
        "      # получение кода языка из инвертированного словаря, возвращаемого gTTS\n",
        "      lang_code = {v: k for k, v in lang.tts_langs().items()}.get(lang_capital)\n",
        "    # синтез речи с помощью gTTS\n",
        "    for i in range(0, len(lines), 4):\n",
        "      export_path = path_to_init + '/' + str(int(i / 4)) + '.wav'\n",
        "      # синтез фразы\n",
        "      aud_gtts = gTTS(lines[i+3], lang = lang_code)\n",
        "      aud_gtts.save(export_path)\n",
        "      if speed != 1:\n",
        "        speedup(export_path, speed)\n",
        "\n",
        "  # ЕСЛИ ВЫБРАЛИ EDGE TTS\n",
        "  elif tool == \"Microsoft Edge TTS\":\n",
        "    if not edge_installed:\n",
        "      # установка\n",
        "      !pip install edge-tts\n",
        "      import asyncio\n",
        "      import edge_tts\n",
        "      from edge_tts import VoicesManager\n",
        "      edge_installed = True\n",
        "    # проверка наличия языка и модели\n",
        "    lang_code = iso639.to_iso639_1(language) # получение кода языка ISO639-1\n",
        "    gender = 'Male' if gender == 'мужской' else 'Female'\n",
        "    if not vm_crtd:\n",
        "      vm = await VoicesManager.create() # создание объекта голосового менеджера\n",
        "      vm_crtd = True\n",
        "    voices = vm.find(Language = lang_code)\n",
        "    if not voices:\n",
        "      print('Данный язык не поддерживается Microsoft Edge TTS!')\n",
        "      raise SystemExit(0)\n",
        "    v_found = False\n",
        "    for v in voices: # проверка на то, что выбранный голос есть для такого языка\n",
        "      if v['ShortName'] == voice:\n",
        "        if not cloning:\n",
        "          if v['Gender'] != gender:\n",
        "            print('Этот голос имеет другой пол. Попробуйте воспользоваться ячейкой ниже, чтобы выбрать подходящий голос.')\n",
        "            raise SystemExit(0)\n",
        "        v_found = True\n",
        "    if not v_found:\n",
        "      print('Голоса с таким названием нет для выбранного язка!')\n",
        "      raise SystemExit(0)\n",
        "\n",
        "    # синтез речи с использованием Edge TTS\n",
        "    for i in range(0, len(lines), 4):\n",
        "      export_path = path_to_init + '/' + str(int(i / 4)) + '.wav'\n",
        "      # синтез фразы\n",
        "      aud_edge = edge_tts.Communicate(line[i+3], voice)\n",
        "      await aud_edge.save(export_path)\n",
        "      if speed != 1:\n",
        "        speedup(export_path, speed)\n",
        "\n",
        "  # ЕСЛИ ВЫБРАЛИ SILERO MODELS\n",
        "  else:\n",
        "    # проверка на наличие языка\n",
        "    if lang_capital not in silero_languages:\n",
        "      print('Данный язык не поддерживается Silero Models!')\n",
        "      raise SystemExit(0)\n",
        "\n",
        "    if not silero_installed:\n",
        "      # установка\n",
        "      !pip install -q torchaudio omegaconf\n",
        "      from pprint import pprint\n",
        "      from omegaconf import OmegaConf\n",
        "      from scipy.io import wavfile\n",
        "      import numpy as np\n",
        "      silero_installed = True\n",
        "    lang_code = iso639.to_iso639_1(language) # получение кода языка ISO639-1\n",
        "    gender = 'male' if gender == 'мужской' else 'female'\n",
        "    # выбор модели\n",
        "    model_id, speaker, ver = choice_silero_model(language, gender=gender)\n",
        "    if not voice and ver == '3-4':\n",
        "      speaker = voice\n",
        "    model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                          model='silero_tts',\n",
        "                                          language=lang_code,\n",
        "                                          speaker=model_id)\n",
        "    model.to(device)\n",
        "    # синтез речи с помощью Silero Models\n",
        "    if ver == '3-4':\n",
        "      sample_rate = 48000\n",
        "      for i in range(0, len(lines), 4):\n",
        "        export_path = path_to_init + '/' + str(int(i / 4)) + '.wav'\n",
        "        # синтез фразы\n",
        "        aud_silero = model.apply_tts(text=lines[i+3], speaker=speaker, sample_rate=sample_rate,\n",
        "                                put_accent=True, put_yo=True)\n",
        "        silero_save(aud_silero, export_path, sample_rate)\n",
        "        if speed != 1:\n",
        "          speedup(export_path, speed)\n",
        "    else:\n",
        "      sample_rate = 16000\n",
        "      for i in range(0, len(lines), 4):\n",
        "        export_path = path_to_init + '/' + str(int(i / 4)) + '.wav'\n",
        "        aud_silero = model.apply_tts(texts=[lines[i+3]], sample_rate=sample_rate)\n",
        "        silero_save(aud_silero, export_path, sample_rate)\n",
        "        if speed != 1:\n",
        "          speedup(export_path, speed)\n",
        "\n",
        "  # скачивание архива\n",
        "  !zip -r synthesized1.zip synthesized1\n",
        "  files.download(\"synthesized1.zip\")\n",
        "\n",
        "  clear_output()\n",
        "  print('Синтезированная речь загружена на ваш компьютер. Вы можете прослушать её и вернуться к работе.')\n",
        "  print('Вы можете, например, загрузить новый SRT файл с непонравившимися фразами и перезапустить эту ячейку.')\n",
        "else:\n",
        "  print('Вы не загрузили текстовый файл!')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2hnmoZwbQYAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Рекомендация по выбору инструмента для синтеза речи\n",
        "\n",
        "# @markdown <font color=\"green\"> Заполните поля ниже, и вам будут предложены подходящие варианты синтеза речи.\n",
        "\n",
        "# @markdown Введите язык (на английском), на котором будет производиться синтез:\n",
        "language = 'english' # @param {type: \"string\"}\n",
        "# @markdown Собираетесь ли вы клонировать голос? (для повышения сходства с оригиналом)\n",
        "cloning = False  # @param {type: \"boolean\"}\n",
        "# @markdown Какой голос предпочтительнее?\n",
        "gender = \"мужской\"  # @param [\"мужской\", \"женский\"]\n",
        "# @markdown Нужно ли вам придать голосу эмоцию?\n",
        "emotions = False  # @param {type: \"boolean\"}\n",
        "\n",
        "# @markdown Примеры голосов Yandex можно послушать на этой странице: https://cloud.yandex.ru/ru/services/speechkit#demo\n",
        "\n",
        "if not gtts_installed:\n",
        "  !pip install gTTS\n",
        "  from gtts import gTTS, lang\n",
        "if not edge_installed:\n",
        "  !pip install edge-tts\n",
        "  import asyncio\n",
        "  import edge_tts\n",
        "  from edge_tts import VoicesManager\n",
        "\n",
        "selected = False # переменная для пометки того, что хотя бы один инструмент подходит\n",
        "\n",
        "language = language.lower()\n",
        "if emotions:\n",
        "  if language in yandex_languages:\n",
        "    header = False\n",
        "    if cloning: # Если голос будет клонироваться, пол голоса модели не важен\n",
        "      for model in yandex_languages.get(language):\n",
        "        if model['roles']:\n",
        "          if not header:\n",
        "            print('Вам могут подойти следующие модели из библиотеки Yandex SpeechKit: \\n')\n",
        "            header = True\n",
        "          print('Имя: ', model['name'], '\\nПол: ', model['gender'], '\\nС возможными амплуа: ', ', '.join(model['roles'], '\\n'))\n",
        "    else:\n",
        "      gender = 'male' if gender == 'мужской' else 'female'\n",
        "      for model in yandex_languages.get(language):\n",
        "        if model['gender'] == gender and model['roles']:\n",
        "          if not header:\n",
        "            print('Вам могут подойти следующие модели из библиотеки Yandex SpeechKit: \\n')\n",
        "            header = True\n",
        "          print('Имя: ', model['name'], '\\nС возможными амплуа: ', ', '.join(model['roles'], '\\n'))\n",
        "  else:\n",
        "    print('К сожалению, эмоции недоступны на выбранном языке.')\n",
        "else:\n",
        "  # Проверка Yandex SpeechKit\n",
        "  if language in yandex_languages.keys():\n",
        "    header = False\n",
        "    if cloning: # Если голос будет клонироваться, пол голоса модели не важен\n",
        "      for model in yandex_languages.get(language):\n",
        "        if not header:\n",
        "          print('Вам могут подойти следующие модели из библиотеки Yandex SpeechKit: \\n')\n",
        "          header = True\n",
        "        print('Имя: ', model['name'], '\\nПол: ', model['gender'], '\\nС возможными амплуа: ', ', '.join(model['roles'], '\\n'))\n",
        "    else:\n",
        "      gender_yandex = 'male' if gender == 'мужской' else 'female'\n",
        "      for model in yandex_languages.get(language):\n",
        "        if model['gender'] == gender_yandex:\n",
        "          if not header:\n",
        "            print('Вам могут подойти следующие модели из библиотеки Yandex SpeechKit: \\n')\n",
        "            header = True\n",
        "          print('Имя: ', model['name'], '\\nС возможными амплуа: ', ', '.join(model['roles'], '\\n'))\n",
        "    if header:\n",
        "      selected = True\n",
        "  # Проверка Coqui TTS\n",
        "  if cloning:\n",
        "    if language == 'english':\n",
        "      print('Также рассмотрите модели XTTSv2 и Tacotron2-DDC_ph из Coqui TTS.')\n",
        "    elif language in xtts_languages:\n",
        "      if selected:\n",
        "        print('Также рассмотрите модель XTTSv2 из Coqui TTS.')\n",
        "      else:\n",
        "        print('Вам может подойти модель XTTSv2 из Coqui TTS.')\n",
        "        selected = True\n",
        "  elif language == 'english' and gender == 'женский':\n",
        "    print('Вам может подойти модель Tacotron2-DDC_ph из Coqui TTS.')\n",
        "    selected = True\n",
        "\n",
        "  language = language[0].upper() + language[1 :]\n",
        "  # Проверка gTTS\n",
        "  lang_available = False\n",
        "  for val in lang.tts_langs().values():\n",
        "    if language in val:\n",
        "      lang_available = True\n",
        "  if lang_available:\n",
        "    if selected:\n",
        "      print('Также рассмотрите gTTS.')\n",
        "    else:\n",
        "      print('Вам может подойти синтез речи с помощью gTTS.')\n",
        "      selected = True\n",
        "    if not cloning:\n",
        "      print('Учтите, что в gTTS нет выбора пола голоса модели.')\n",
        "  # Проверка edge-tts\n",
        "  lang_code = iso639.to_iso639_1(language) # получение кода языка ISO639-1\n",
        "  gender_edge = 'Male' if gender == 'мужской' else 'Female'\n",
        "  if not vm_crtd:\n",
        "    vm = await VoicesManager.create()\n",
        "    vm_crtd = True\n",
        "  if cloning:\n",
        "    voices = vm.find(Language = lang_code)\n",
        "    if voices:\n",
        "      if selected:\n",
        "        print('Также рассмотрите Microsoft Edge TTS.')\n",
        "        print('Вам могут подойти следующие голоса:')\n",
        "      else:\n",
        "        print('Вам могут подойти следующие голоса Microsoft Edge TTS:')\n",
        "        selected = True\n",
        "      for voice in voices:\n",
        "        print(voice['ShortName'], ', пол: ', voice['Gender'])\n",
        "  else:\n",
        "    voices = vm.find(Gender = gender_edge, Language = lang_code)\n",
        "    if voices:\n",
        "      if selected:\n",
        "        print('Также рассмотрите Microsoft Edge TTS.')\n",
        "        print('Вам могут подойти следующие голоса:')\n",
        "      else:\n",
        "        print('Вам могут подойти следующие голоса Microsoft Edge TTS:')\n",
        "        selected = True\n",
        "      for voice in voices:\n",
        "        print(voice['ShortName'])\n",
        "  # Проверка Silero Models\n",
        "  if language in silero_languages:\n",
        "    if selected:\n",
        "      print('Также можно посоветовать Silero Models.')\n",
        "    else:\n",
        "      print('Вам может подойти Silero Models.')\n",
        "      selected = True\n",
        "    print('Совет: поэкспериментируйте, выбирая голос в ячейке ниже.') #???\n",
        "  if not selected:\n",
        "    print('К сожалению, моделей с запрашиваемыми параметрами нет.')"
      ],
      "metadata": {
        "id": "beWVA59KeqWX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Тестирование голосов\n",
        "\n",
        "# @markdown Выберите синтезатор для тестирования:\n",
        "tool = \"gTTS\" # @param [\"gTTS\", \"Microsoft Edge TTS\", \"Silero Models\"]\n",
        "\n",
        "# @markdown Введите язык (для gTTS и Silero Models), на английском:\n",
        "language = 'english' # @param {type: \"string\"}\n",
        "\n",
        "# @markdown Введите голоса (для Microsoft Edge TTS и Silero Models):\n",
        "voice_name = 'ru-RU-DmitryNeural' # @param {type: \"string\"}\n",
        "\n",
        "# @markdown Выберите пол голоса (для некоторых языков Silero):\n",
        "gender = 'male' # @param [\"male\", \"female\"]\n",
        "\n",
        "# @markdown <font color=\"darkblue\"> *Голоса Silero на выбор, которые вы можете протестировать:*\n",
        "\n",
        "# @markdown * Русский: 'aidar', 'baya', 'kseniya', 'xenia', 'eugene'\n",
        "\n",
        "# @markdown * Английский: en_0-en_117\n",
        "\n",
        "# @markdown * Немецкий: 'bernd_ungerer', 'eva_k', 'friedrich', 'hokuspokus', 'karlsson'\n",
        "\n",
        "# @markdown * Испанский: es_0-es_2\n",
        "\n",
        "# @markdown * Французский: fr_0-fr_5\n",
        "\n",
        "# @markdown * Калмыцкий: 'erdni', 'delghir'\n",
        "\n",
        "# @markdown * Украинский 'aidar', 'baya', 'kseniya', 'xenia', 'eugene'\n",
        "\n",
        "# @markdown * Для индийских языков доступны женские и мужские, кроме Manipuri (только женский).\n",
        "\n",
        "# @markdown * Кириллические языки: 'b_bulb', 'b_bulc', 'b_tat', 'b_ru', 'b_tyv', 'b_uzb', 'b_che', 'b_kalmyk',\n",
        "# @markdown 'b_sah', 'b_myv', 'b_kjh', 'b_lez', 'b_krc', 'b_cv', 'b_udm', 'b_bashkir','b_nog','b_oss', 'b_ava',\n",
        "# @markdown 'b_mhr', 'b_kpv', 'b_mrj', 'kz_M1', 'kz_M2', 'kz_F3', 'kz_F1', 'kz_F2', 'cv_ekaterina', 'marat_tt',\n",
        "# @markdown 'kalmyk_erdni', 'kalmyk_delghir'\n",
        "\n",
        "# @markdown <font color=\"darkblue\"> *Для остальных доступных языков выбора нет (одна модель).*\n",
        "\n",
        "# @markdown Введите текст:\n",
        "text = 'Hello, this is a test text.' # @param {type: \"string\"}\n",
        "\n",
        "\n",
        "if tool == \"gTTS\":\n",
        "  if not gtts_installed:\n",
        "    !pip install gTTS\n",
        "    from gtts import gTTS, lang\n",
        "    gtts_installed = True\n",
        "  # синтез gTTS\n",
        "  lang_code = iso639.to_iso639_1(language) # получение кода языка ISO639-1\n",
        "  test_aud = gTTS(text, lang=lang_code)\n",
        "  test_aud.save('test_aud.mp3')\n",
        "  clear_output()\n",
        "  # отображение аудио для проигрывания в среде\n",
        "  display(Audio('test_aud.mp3'))\n",
        "\n",
        "elif tool == \"Microsoft Edge TTS\":\n",
        "  if not edge_installed:\n",
        "    !pip install edge-tts\n",
        "    import asyncio\n",
        "    import edge_tts\n",
        "    from edge_tts import VoicesManager\n",
        "    edge_installed = True\n",
        "  # синтез edge-tts\n",
        "  test_aud = edge_tts.Communicate(text, voice_name)\n",
        "  await test_aud.save('test_aud.mp3')\n",
        "  clear_output()\n",
        "  display(Audio('test_aud.mp3'))\n",
        "\n",
        "else:\n",
        "  lang_code = iso639.to_iso639_1(language) # получение кода языка ISO639-1\n",
        "  if not silero_installed:\n",
        "    !pip install -q torchaudio omegaconf\n",
        "    from pprint import pprint\n",
        "    from omegaconf import OmegaConf\n",
        "    from scipy.io import wavfile\n",
        "    import numpy as np\n",
        "    silero_installed = True\n",
        "  # синтез Silero\n",
        "  model_id, voice, ver = choice_silero_model(language, gender=gender)\n",
        "  # Проверяем доступность GPU\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  if not voice and ver == '3-4':\n",
        "    voice = voice_name\n",
        "  model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                       model='silero_tts',\n",
        "                                       language=lang_code,\n",
        "                                       speaker=model_id)\n",
        "  model.to(device)\n",
        "  if ver == '3-4':\n",
        "    sample_rate = 48000\n",
        "    audio = model.apply_tts(text=text,\n",
        "                            speaker=voice,\n",
        "                            sample_rate=sample_rate,\n",
        "                            put_accent=True,\n",
        "                            put_yo=True)\n",
        "    clear_output()\n",
        "    display(Audio(test_audio, rate = sample_rate))\n",
        "  else:\n",
        "    sample_rate = 16000\n",
        "    audio = model.apply_tts(texts=[text],\n",
        "                            sample_rate=sample_rate)\n",
        "    clear_output()\n",
        "    display(Audio(audio[0], rate=sample_rate))"
      ],
      "metadata": {
        "id": "tfg7QnBDWbmS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "85122ead-46a9-4c41-dd91-08485c61df87",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" >\n",
              "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Клонирование голоса"
      ],
      "metadata": {
        "id": "6Tz7lmci99Rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Выберите инструмент для клонирования:\n",
        "tool = \"Coqui freeVC24\" # @param [\"Coqui freeVC24\", \"OpenVoice\"]\n",
        "\n",
        "# проверка на наличие файла для клонирования\n",
        "if os.path.isfile(clone_sample):\n",
        "  if os.path.exists(path_to_init):\n",
        "    if tool == \"Coqui freeVC24\":\n",
        "      if not coqui_installed:\n",
        "        # установка TTS\n",
        "        !pip install TTS\n",
        "        from TTS.api import TTS\n",
        "        coqui_installed = True\n",
        "        # Получить устройство\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "      # загрузка модели для клонирования голоса\n",
        "      tts = TTS(model_name = \"voice_conversion_models/multilingual/vctk/freevc24\", progress_bar = False).to(device)\n",
        "\n",
        "      path_to_cloned = '/content/cloned'\n",
        "      !mkdir $path_to_cloned\n",
        "      for fn in os.listdir(path_to_init):\n",
        "        # клонирование голоса\n",
        "        tts.voice_conversion_to_file(source_wav = path_to_init + '/' + fn,\n",
        "                                     target_wav = clone_sample,\n",
        "                                     file_path = path_to_cloned + '/' + fn)\n",
        "      !rm -rf $path_to_init\n",
        "      os.rename(path_to_cloned, path_to_init)\n",
        "    else:\n",
        "      %cd /content\n",
        "      !git clone https://github.com/myshell-ai/OpenVoice\n",
        "      %cd /content/OpenVoice\n",
        "\n",
        "      !pip install pytorch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 pytorch-cuda==11.7\n",
        "      !pip install -r requirements.txt\n",
        "\n",
        "      from openvoice import se_extractor\n",
        "      from openvoice.api import ToneColorConverter\n",
        "\n",
        "      !mkdir /content/OpenVoice/checkpoints\n",
        "      !wget 'https://myshell-public-repo-hosting.s3.amazonaws.com/checkpoints_1226.zip' -O '/content/OpenVoice/checkpoints/checkpoints_1226.zip'\n",
        "      !unzip /content/OpenVoice/checkpoints/checkpoints_1226.zip -d /content/OpenVoice/checkpoints\n",
        "\n",
        "      ckpt_converter = '/content/OpenVoice/checkpoints/checkpoints/converter'\n",
        "      device = 'cuda:0'\n",
        "      tone_color_converter = ToneColorConverter(f'{ckpt_converter}/config.json', device=device)\n",
        "      tone_color_converter.load_ckpt(f'{ckpt_converter}/checkpoint.pth')\n",
        "\n",
        "      path_to_cloned = '/content/cloned'\n",
        "      !mkdir $path_to_cloned\n",
        "      reference_speaker = clone_sample\n",
        "      target_se, audio_name = se_extractor.get_se(reference_speaker, tone_color_converter, vad = True)\n",
        "      for fn in os.listdir('/content/synthesized1'):\n",
        "        base_speaker = '/content/synthesized1/' + fn\n",
        "        source_se, audio_name = se_extractor.get_se(base_speaker, tone_color_converter, vad = True)\n",
        "        src_path = '/content/synthesized1/' + fn\n",
        "        save_path = path_to_cloned + '/' + fn\n",
        "        # клонирование голоса\n",
        "        encode_message = \"@MyShell\"\n",
        "        tone_color_converter.convert(\n",
        "            audio_src_path = src_path,\n",
        "            src_se = source_se,\n",
        "            tgt_se = target_se,\n",
        "            output_path = save_path,\n",
        "            message = encode_message)\n",
        "      !rm -rf $path_to_init\n",
        "      os.rename(path_to_cloned, path_to_init)\n",
        "      used_openvoice = True\n",
        "      !zip -r synthesized1.zip synthesized1 # на всякий случай\n",
        "    download = input('Нужно ли сохранить zip-архив с результатами? y/n ')\n",
        "    if download == 'y':\n",
        "      # скачивание архива\n",
        "      !zip -r synthesized1.zip synthesized1\n",
        "      files.download(\"synthesized1.zip\")\n",
        "    clear_output()\n",
        "  else:\n",
        "    print('Отсутствует папка с синтезированной речью. Похоже, что вы не синтезировали речь, либо не загрузили её в среду.')\n",
        "else:\n",
        "  print('Вы не загрузили образец голоса для клонирования. Пожалуйста, вернитесь ко второму разделу.')"
      ],
      "metadata": {
        "id": "-sMng8oMOLI6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Замена аудиодорожки в видео на синтезированную"
      ],
      "metadata": {
        "id": "aFSyY92r7FHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Нарезка видео для второго варианта замены аудиодороджки (может длиться час и более)\n",
        "\n",
        "# @markdown Скачать zip-архивы с получившимися фрагментами (2 шт.)?\n",
        "download_file = False # @param {type: \"boolean\"}\n",
        "\n",
        "if used_openvoice == True:\n",
        "  !pip install ffmpeg-python\n",
        "  import ffmpeg\n",
        "  path_to_video = '/content/vid.mp4'\n",
        "  path_to_text = '/content/subtitles.srt'\n",
        "path_to_fragments = '/content/fragments'\n",
        "path_to_intermediate = '/content/int_fragms'\n",
        "!mkdir /content/fragments\n",
        "!mkdir /content/int_fragms\n",
        "\n",
        "if os.path.isfile(path_to_video) and os.path.isfile(path_to_text):\n",
        "  # считываем из файла строки\n",
        "  txtfile = open(path_to_text, 'r', encoding = 'utf-8')\n",
        "  lines = [''] + txtfile.read().split('\\n')\n",
        "  txtfile.close()\n",
        "\n",
        "  # копируем заставку\n",
        "  !ffmpeg -y -i $path_to_video -to {str_to_time(lines[2][:lines[2].find(' ')])} -async 1 /content/int_fragms/s.mp4\n",
        "\n",
        "  for i in range(0, len(lines), 4):\n",
        "    out_path1 = path_to_fragments + '/' + str(int(i / 4)) + '.mp4'\n",
        "    out_path2 = path_to_intermediate + '/' + str(int(i / 4)) + '.mp4'\n",
        "    start = str_to_time(lines[i + 2][:lines[i + 2].find(' ')]) # в секундах, float\n",
        "    end = str_to_time(lines[i + 2][lines[i + 2].rfind(' ') + 1:])\n",
        "    # копирование части видео по таймингу\n",
        "    !ffmpeg -y -i $path_to_video -ss {start + 0.001} -to {end} -async 1 $out_path1\n",
        "    if i != len(lines) - 4: # не последний тайминг\n",
        "      next_start = str_to_time(lines[i + 6][:lines[i + 6].find(' ')])\n",
        "      if next_start - end > 0:\n",
        "        !ffmpeg -y -i $path_to_video -ss {end + 0.001} -to {next_start} -async 1 $out_path2\n",
        "    else:\n",
        "      if round(video_duration(path_to_video), 3) > end:\n",
        "        !ffmpeg -y -i $path_to_video -ss {end + 0.001} -async 1 $out_path2\n",
        "  clear_output()\n",
        "\n",
        "  print('Фрагменты успешно нарезаны. После этого в нижней ячейке выберите второй вариант.')\n",
        "  if download_file:\n",
        "    !zip -r /content/fragments.zip /content/fragments\n",
        "    !zip -r /content/int_fragms.zip /content/int_fragms\n",
        "    files.download(\"/content/fragments.zip\")\n",
        "    files.download(\"/content/int_fragms.zip\")\n",
        "    clear_output()\n",
        "    print('Они будут автоматически загружены в zip-архивах на ваш компьютер. Если собираетесь продолжить позже, выгрузите их в соответсвующей ячейке раздела загрузок.')\n",
        "else:\n",
        "  print('Похоже, вы не загрузили видео или текстовый файл (или всё вместе).')"
      ],
      "metadata": {
        "id": "J7OfQEpxb-Yf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Выберите способ:\n",
        "mode = \"Простое наложение аудио по таймингам\" # @param [\"Простое наложение аудио по таймингам\", \"Растянуть/сузить видео, чтобы подходило под фразы\"]\n",
        "# @markdown Замедлять фразы для лучшего совпадения со временем произношения? (для 1 варианта)\n",
        "slow_aud = False # @param {type: \"boolean\"}\n",
        "# @markdown Ограничивать замедление/ускорение? (для обоих вариантов) Это нужно для того, чтобы не было слишком большой разницы между скоростями фраз или видеофрагментов в итоговом видео, если синтезированная фраза намного длиннее/короче оригинальной.\n",
        "limit = True # @param {type: \"boolean\"}\n",
        "# @markdown Скачать результаты?\n",
        "download_file = True # @param {type: \"boolean\"}\n",
        "\n",
        "ok = True\n",
        "\n",
        "if os.path.exists(path_to_init) and os.path.isfile(path_to_text):\n",
        "  !mkdir $path_to_synth\n",
        "\n",
        "  # чтение файла\n",
        "  txtfile = open(path_to_text, \"r\", encoding = \"utf-8\")\n",
        "  lines = [''] + txtfile.read().split('\\n')\n",
        "  txtfile.close()\n",
        "\n",
        "  if mode == \"Простое наложение аудио по таймингам\":\n",
        "    if os.path.isfile(path_to_video):\n",
        "      path_to_screensaver = '/content/s.mp4'\n",
        "      # вырезание заставки из видео\n",
        "      !ffmpeg -y -i $path_to_video -to {str_to_time(lines[2][:lines[2].find(' ')])} -async 1 $path_to_screensaver\n",
        "\n",
        "      for i in range(0, len(lines), 4):\n",
        "        old_path = path_to_init + '/' + str(int(i / 4)) + '.wav'\n",
        "        new_path = path_to_synth + '/' + str(int(i / 4)) + '.wav'\n",
        "        # изменение продолжительности аудио в соответствии с таймингом\n",
        "        check_duration(old_path, new_path, str_to_time(lines[i+2][:lines[i+2].find(' ')]),\n",
        "                       str_to_time(lines[i+2][lines[i+2].rfind(' ') + 1:]), slow_aud, limit)\n",
        "        # добавление паузы после фразы до следующего тайминга или до конца\n",
        "        audio = AudioSegment.from_wav(new_path)\n",
        "        aud_len = len(audio) / 1000\n",
        "        if i != len(lines) - 4: # если не последний тайминг\n",
        "          # продолжительность от начала текущего сегмента до начала следующего (в секундах)\n",
        "          fragm_dur = str_to_time(lines[i+6][:lines[i+6].find(' ')]) - str_to_time(lines[i+2][:lines[i+2].find(' ')])\n",
        "          if aud_len < fragm_dur:\n",
        "            add_pause(new_path, new_path, fragm_dur - aud_len)\n",
        "        else: # последний тайминг\n",
        "          # продолжительность от начала текущего сегмента до конца видео (в секундах)\n",
        "          fragm_dur = video_duration(path_to_video) - str_to_time(lines[i+2][:lines[i+2].find(' ')])\n",
        "          if aud_len < fragm_dur:\n",
        "            add_pause(new_path, new_path, fragm_dur - aud_len)\n",
        "    else:\n",
        "      print('Вы не загрузили видео. Необходимо сделать это в разделе загрузок.')\n",
        "      ok = False\n",
        "\n",
        "  else:\n",
        "    path_to_fragments = '/content/fragments'\n",
        "    path_to_intermediate = '/content/int_fragms'\n",
        "    path_to_screensaver = '/content/int_fragms/s.mp4'\n",
        "\n",
        "    if (os.path.exists(path_to_fragments) and os.path.exists(path_to_intermediate)):\n",
        "      for i in range(0, len(lines), 4):\n",
        "        old_path = path_to_init + '/' + str(int(i / 4)) + '.wav'\n",
        "        new_path = path_to_synth + '/' + str(int(i / 4)) + '.wav'\n",
        "        vid_path = path_to_fragments + '/' + str(int(i / 4)) + '.mp4'\n",
        "        pause_path = path_to_intermediate + '/' + str(int(i / 4)) + '.mp4'\n",
        "\n",
        "        # замедление/ускорение видеофрагмента, если синтезированная фраза длиннее/короче\n",
        "        check_vid_duration(old_path, vid_path, limit)\n",
        "        if os.path.exists(pause_path): # есть следующий фрагмент видео (тайминги не одинаковые для конца и начала след. фразы)\n",
        "            # добавление паузы, равной продолжительности следующего видеофрагмента\n",
        "            add_pause(old_path, new_path, video_duration(pause_path))\n",
        "        else: # иначе всё равно копируем в новую папку\n",
        "          !cp $old_path $new_path\n",
        "    else:\n",
        "      print('Вы не нарезали видео на фрагменты. Это можно сделать в ячейке выше. Или загрузите фрагменты в разделе загрузок.')\n",
        "      ok = False\n",
        "\n",
        "  if ok:\n",
        "    # склеиваем все фразы в целую аудиодорожку\n",
        "    synthesized = [path_to_synth + '/' + item for item in os.listdir(path_to_synth) if '.ipynb' not in item]\n",
        "    synthesized = sorted(synthesized, key = extract_number)\n",
        "    start = str_to_time(lines[2][:lines[2].find(' ')])\n",
        "    if start: # фраза начинается не с самого начала\n",
        "      combined = AudioSegment.silent(duration = start * 1000) # тишина\n",
        "    else:\n",
        "      combined = None\n",
        "    for fragment in synthesized:\n",
        "      audio = AudioSegment.from_file(fragment, format = \"wav\")\n",
        "      if combined is None:\n",
        "          combined = audio\n",
        "      else:\n",
        "          combined += audio\n",
        "    # сохранение результата\n",
        "    combined.export('/content/synthesized_speech.wav', format = \"wav\")\n",
        "\n",
        "    # Наложение на видео новой аудиодорожки\n",
        "    if mode == \"Растянуть/сузить видео, чтобы подходило под фразы\":\n",
        "      # объединение изменённых видеофрагментов\n",
        "      fragments = [path_to_fragments + '/' + item for item in os.listdir(path_to_fragments) if '.ipynb' not in item]\n",
        "      fragments = sorted(fragments, key = extract_number)\n",
        "      int_fragms = [path_to_intermediate + '/' + item for item in os.listdir(path_to_intermediate) if '.ipynb' not in item and 's' not in item]\n",
        "      int_fragms = sorted(int_fragms, key = extract_number)\n",
        "      loaded_video_list = []\n",
        "      loaded_video_list.append(VideoFileClip(path_to_intermediate + '/s.mp4')) # заставка\n",
        "      for i, vid in enumerate(fragments):\n",
        "        loaded_video_list.append(VideoFileClip(vid))\n",
        "        next_fragm = path_to_intermediate + '/' + str(i) + '.mp4'\n",
        "        if os.path.exists(next_fragm): # если существует промежуточный фрагмент\n",
        "          loaded_video_list.append(VideoFileClip(next_fragm))\n",
        "      concatenate_clip = concatenate_videoclips(loaded_video_list)\n",
        "      if os.path.exists(path_to_video):\n",
        "        os.remove(path_to_video)\n",
        "      concatenate_clip.write_videofile(path_to_video, logger = None)\n",
        "\n",
        "      # исправление файла с субтитрами с помощью списка times\n",
        "      subs_path = '/content/new_subs.srt'\n",
        "      for i in range(0, len(lines), 4):\n",
        "        audio_length = times[int(i / 4)] # в секундах\n",
        "        if i == 0: # первый тайминг\n",
        "          start_timing = lines[i + 2][:lines[i + 2].find(' ')]\n",
        "          end_timing = time_to_str(str_to_time(start_timing) + audio_length)\n",
        "          lines[i + 2] = start_timing + ' --> ' + end_timing\n",
        "          pause = path_to_intermediate + '/' + str(int(i / 4)) + '.mp4'\n",
        "          if os.path.exists(pause):\n",
        "            start_timing = time_to_str(str_to_time(end_timing) + video_duration(pause))\n",
        "          else:\n",
        "            start_timing = end_timing\n",
        "        elif i == len(lines) - 4: # последний\n",
        "          end_timing = time_to_str(str_to_time(start_timing) + audio_length)\n",
        "          lines[i + 2] = start_timing + ' --> ' + end_timing\n",
        "        else: # средний\n",
        "          end_timing = time_to_str(str_to_time(start_timing) + audio_length)\n",
        "          lines[i + 2] = start_timing + ' --> ' + end_timing\n",
        "          pause = path_to_intermediate + '/' + str(int(i / 4)) + '.mp4'\n",
        "          if os.path.exists(pause):\n",
        "            start_timing = time_to_str(str_to_time(end_timing) + video_duration(pause))\n",
        "          else:\n",
        "            start_timing = end_timing\n",
        "\n",
        "      txt_file = open(subs_path, 'w', encoding = \"utf-8\")\n",
        "      for line in lines[1:-1]:\n",
        "        txt_file.write(line + '\\n')\n",
        "      if len(lines) != 1:\n",
        "        txt_file.write(lines[-1])\n",
        "      txt_file.close()\n",
        "\n",
        "    # добавление в начало аудиодорожки заставки на случай, если она была музыкальной\n",
        "    screensaver = VideoFileClip(path_to_screensaver)\n",
        "    music = screensaver.audio\n",
        "    music.write_audiofile('/content/music.wav')\n",
        "    full_audio = AudioSegment.from_wav('/content/synthesized_speech.wav')\n",
        "    full_audio = AudioSegment.from_wav('/content/music.wav') + full_audio[screensaver.duration * 1000:]\n",
        "    full_audio.export('/content/synthesized_speech1.wav', format = 'wav')\n",
        "\n",
        "    # Наложение на видео аудиодорожки\n",
        "    !ffmpeg -i /content/vid.mp4 -i /content/synthesized/synthesized_speech1.wav -c:v copy -c:a aac -strict experimental -map 0:v:0 -map 1:a:0 /content/result.mp4\n",
        "\n",
        "    clear_output()\n",
        "\n",
        "    if download_file:\n",
        "      files.download(\"/content/result.mp4\")\n",
        "      if os.path.isfile(\"/content/new_subs.srt\"):\n",
        "        files.download(\"/content/new_subs.srt\")\n",
        "      clear_output()\n",
        "    print('Поздравляем! Всё готово. Результаты находятся по пути: /content/result.mp4 - видео, /content/new_subs.srt - новые субтитры (если был выбран второй способ).')\n",
        "else:\n",
        "  if not os.path.exists(path_to_init):\n",
        "    print('Не найдена папка с синтезированной речью. Возможно, вы её не синтезировали. Или вы не загрузили архив.')\n",
        "  else:\n",
        "    print('Вы не загрузили текст. Вы можете сделать это в разделе загрузок.')"
      ],
      "metadata": {
        "id": "z_UlHkQ880ne",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Размонтировать Google Drive"
      ],
      "metadata": {
        "id": "o3fSu0qeDQur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "bS30o7NRDT1-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}